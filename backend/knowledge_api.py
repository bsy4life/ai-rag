# knowledge_api.py - çŸ¥è­˜åº«æ–‡ä»¶ç®¡ç† API
"""
æä¾›çŸ¥è­˜åº«æ–‡ä»¶çš„ä¸Šå‚³ã€è½‰æ›ã€åˆªé™¤å’Œç´¢å¼•ç®¡ç†åŠŸèƒ½
æ”¯æ´ï¼šPDF, DOCX, MD, TXT, CSV æª”æ¡ˆ
"""

import os
import shutil
import subprocess
import tempfile
import logging
from datetime import datetime
from typing import List, Optional, Dict, Any
from pathlib import Path

from fastapi import APIRouter, UploadFile, File, HTTPException, Form
from fastapi.responses import JSONResponse

# æœ¬åœ°æ¨¡çµ„
from vectordb import DATA_DIR, BUSINESS_DATA_DIR, BUSINESS_CSV_FILE

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/knowledge", tags=["knowledge"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ALLOWED_EXTENSIONS = {'.pdf', '.docx', '.doc', '.md', '.txt', '.csv', '.rtf'}
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(BUSINESS_DATA_DIR, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å·¥å…·å‡½æ•¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_file_extension(filename: str) -> str:
    """å–å¾—æª”æ¡ˆå‰¯æª”åï¼ˆå°å¯«ï¼‰"""
    return Path(filename).suffix.lower()

def is_allowed_file(filename: str) -> bool:
    """æª¢æŸ¥æª”æ¡ˆé¡å‹æ˜¯å¦å…è¨±"""
    return get_file_extension(filename) in ALLOWED_EXTENSIONS

def safe_filename(filename: str) -> str:
    """ç”¢ç”Ÿå®‰å…¨çš„æª”æ¡ˆåç¨±"""
    # ç§»é™¤è·¯å¾‘åˆ†éš”ç¬¦å’Œç‰¹æ®Šå­—å…ƒ
    name = os.path.basename(filename)
    # ä¿ç•™ä¸­æ–‡å­—å…ƒ
    safe_chars = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.-_')
    result = []
    for char in name:
        if char in safe_chars or '\u4e00' <= char <= '\u9fff':
            result.append(char)
        elif char in ' ':
            result.append('_')
    return ''.join(result) or 'unnamed'

def convert_pdf_to_markdown(pdf_path: str, output_path: str) -> Dict[str, Any]:
    """
    å°‡ PDF è½‰æ›ç‚º Markdown
    ä½¿ç”¨ pdfplumber æå–æ–‡å­—å’Œè¡¨æ ¼
    """
    try:
        import pdfplumber
        
        content_parts = []
        tables_count = 0
        pages_count = 0
        
        with pdfplumber.open(pdf_path) as pdf:
            pages_count = len(pdf.pages)
            
            for i, page in enumerate(pdf.pages):
                # æå–æ–‡å­—
                text = page.extract_text()
                if text:
                    content_parts.append(f"## Page {i + 1}\n\n{text}")
                
                # æå–è¡¨æ ¼
                tables = page.extract_tables()
                for j, table in enumerate(tables):
                    if table and len(table) > 0:
                        tables_count += 1
                        # è½‰æ›ç‚º Markdown è¡¨æ ¼
                        md_table = convert_table_to_markdown(table)
                        content_parts.append(f"\n### Table {j + 1} (Page {i + 1})\n\n{md_table}")
        
        # çµ„åˆå…§å®¹
        full_content = '\n\n'.join(content_parts)
        
        # å¯«å…¥æª”æ¡ˆ
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"# {Path(pdf_path).stem}\n\n")
            f.write(f"> Converted from PDF on {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
            f.write(full_content)
        
        return {
            "success": True,
            "pages": pages_count,
            "tables": tables_count,
            "output_path": output_path
        }
        
    except ImportError:
        # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ pdftotext
        return convert_pdf_with_pdftotext(pdf_path, output_path)
    except Exception as e:
        return {"success": False, "error": str(e)}

def convert_pdf_with_pdftotext(pdf_path: str, output_path: str) -> Dict[str, Any]:
    """ä½¿ç”¨ pdftotext å‘½ä»¤è¡Œå·¥å…·è½‰æ› PDF"""
    try:
        # ä½¿ç”¨ pdftotext ä¿ç•™æ’ç‰ˆ
        result = subprocess.run(
            ['pdftotext', '-layout', pdf_path, '-'],
            capture_output=True,
            text=True,
            timeout=60
        )
        
        if result.returncode != 0:
            return {"success": False, "error": f"pdftotext failed: {result.stderr}"}
        
        content = result.stdout
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"# {Path(pdf_path).stem}\n\n")
            f.write(f"> Converted from PDF on {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
            f.write("```\n")
            f.write(content)
            f.write("\n```\n")
        
        return {"success": True, "output_path": output_path, "method": "pdftotext"}
        
    except FileNotFoundError:
        return {"success": False, "error": "pdftotext not installed. Install with: apt-get install poppler-utils"}
    except subprocess.TimeoutExpired:
        return {"success": False, "error": "PDF conversion timeout"}
    except Exception as e:
        return {"success": False, "error": str(e)}

def convert_docx_to_markdown(docx_path: str, output_path: str) -> Dict[str, Any]:
    """
    å°‡ DOCX è½‰æ›ç‚º Markdown
    ä½¿ç”¨ pandoc é€²è¡Œè½‰æ›
    """
    try:
        # ä½¿ç”¨ pandoc è½‰æ›
        result = subprocess.run(
            ['pandoc', docx_path, '-o', output_path, '--wrap=none'],
            capture_output=True,
            text=True,
            timeout=60
        )
        
        if result.returncode != 0:
            return {"success": False, "error": f"pandoc failed: {result.stderr}"}
        
        return {"success": True, "output_path": output_path, "method": "pandoc"}
        
    except FileNotFoundError:
        return {"success": False, "error": "pandoc not installed. Install with: apt-get install pandoc"}
    except subprocess.TimeoutExpired:
        return {"success": False, "error": "DOCX conversion timeout"}
    except Exception as e:
        return {"success": False, "error": str(e)}

def convert_table_to_markdown(table: List[List]) -> str:
    """å°‡è¡¨æ ¼è³‡æ–™è½‰æ›ç‚º Markdown æ ¼å¼"""
    if not table or len(table) == 0:
        return ""
    
    # æ¸…ç† None å€¼
    cleaned = []
    for row in table:
        cleaned_row = [str(cell) if cell else "" for cell in row]
        cleaned.append(cleaned_row)
    
    if len(cleaned) == 0:
        return ""
    
    # å–å¾—æœ€å¤§æ¬„ä½æ•¸
    max_cols = max(len(row) for row in cleaned)
    
    # æ¨™æº–åŒ–æ¬„ä½æ•¸
    for row in cleaned:
        while len(row) < max_cols:
            row.append("")
    
    # å»ºç«‹ Markdown è¡¨æ ¼
    lines = []
    
    # æ¨™é¡Œè¡Œ
    lines.append("| " + " | ".join(cleaned[0]) + " |")
    
    # åˆ†éš”è¡Œ
    lines.append("| " + " | ".join(["---"] * max_cols) + " |")
    
    # è³‡æ–™è¡Œ
    for row in cleaned[1:]:
        lines.append("| " + " | ".join(row) + " |")
    
    return '\n'.join(lines)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# API ç«¯é»
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.get("/files")
async def list_knowledge_files():
    """åˆ—å‡ºæ‰€æœ‰çŸ¥è­˜åº«æ–‡ä»¶"""
    files = []
    
    # æŠ€è¡“æ–‡æª”
    if os.path.exists(DATA_DIR):
        for filename in os.listdir(DATA_DIR):
            filepath = os.path.join(DATA_DIR, filename)
            if os.path.isfile(filepath):
                stat = os.stat(filepath)
                files.append({
                    "name": filename,
                    "path": filepath,
                    "type": "technical",
                    "size": stat.st_size,
                    "modified": datetime.fromtimestamp(stat.st_mtime).isoformat()
                })
    
    # æ¥­å‹™è³‡æ–™
    if os.path.exists(BUSINESS_DATA_DIR):
        for filename in os.listdir(BUSINESS_DATA_DIR):
            filepath = os.path.join(BUSINESS_DATA_DIR, filename)
            if os.path.isfile(filepath):
                stat = os.stat(filepath)
                files.append({
                    "name": filename,
                    "path": filepath,
                    "type": "business",
                    "size": stat.st_size,
                    "modified": datetime.fromtimestamp(stat.st_mtime).isoformat()
                })
    
    # æ’åºï¼šæœ€æ–°çš„åœ¨å‰
    files.sort(key=lambda x: x['modified'], reverse=True)
    
    return {
        "files": files,
        "total": len(files),
        "technical_dir": DATA_DIR,
        "business_dir": BUSINESS_DATA_DIR
    }

@router.post("/upload")
async def upload_file(
    file: UploadFile = File(...),
    doc_type: str = Form("technical"),
    auto_convert: bool = Form(True)
):
    """
    ä¸Šå‚³æ–‡ä»¶åˆ°çŸ¥è­˜åº«
    
    Parameters:
    - file: ä¸Šå‚³çš„æª”æ¡ˆ
    - doc_type: æ–‡ä»¶é¡å‹ (technical/business)
    - auto_convert: æ˜¯å¦è‡ªå‹•è½‰æ› PDF/DOCX ç‚º Markdown
    """
    # é©—è­‰æª”æ¡ˆ
    if not file.filename:
        raise HTTPException(status_code=400, detail="No filename provided")
    
    ext = get_file_extension(file.filename)
    if ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(
            status_code=400, 
            detail=f"File type not allowed. Allowed: {', '.join(ALLOWED_EXTENSIONS)}"
        )
    
    # ç¢ºå®šç›®æ¨™ç›®éŒ„
    if doc_type == "business":
        target_dir = BUSINESS_DATA_DIR
    else:
        target_dir = DATA_DIR
    
    os.makedirs(target_dir, exist_ok=True)
    
    # ç”¢ç”Ÿå®‰å…¨æª”å
    safe_name = safe_filename(file.filename)
    temp_path = os.path.join(tempfile.gettempdir(), safe_name)
    
    try:
        # å„²å­˜ä¸Šå‚³çš„æª”æ¡ˆ
        content = await file.read()
        
        if len(content) > MAX_FILE_SIZE:
            raise HTTPException(status_code=400, detail=f"File too large. Max: {MAX_FILE_SIZE // 1024 // 1024}MB")
        
        with open(temp_path, 'wb') as f:
            f.write(content)
        
        result = {
            "filename": safe_name,
            "original_name": file.filename,
            "size": total,
            "type": doc_type
        }
        
        # è‡ªå‹•è½‰æ›
        if auto_convert and ext in {'.pdf', '.docx', '.doc', '.rtf'}:
            output_name = Path(safe_name).stem + '.md'
            output_path = os.path.join(target_dir, output_name)
            
            logger.info(f"ğŸ“„ é–‹å§‹è½‰æ› {ext} æª”æ¡ˆ: {safe_name} -> {output_name}")
            
            if ext == '.pdf':
                convert_result = convert_pdf_to_markdown(temp_path, output_path)
            else:
                convert_result = convert_docx_to_markdown(temp_path, output_path)
            
            logger.info(f"ğŸ“„ è½‰æ›çµæœ: {convert_result}")
            
            if convert_result.get("success"):
                result["converted"] = True
                result["converted_file"] = output_name
                result["conversion_info"] = convert_result
                
                # ç¢ºèªæª”æ¡ˆå·²å»ºç«‹
                if os.path.exists(output_path):
                    logger.info(f"âœ… è½‰æ›å¾Œæª”æ¡ˆå·²å»ºç«‹: {output_path}")
                else:
                    logger.error(f"âŒ è½‰æ›å¾Œæª”æ¡ˆä¸å­˜åœ¨: {output_path}")
                
                # ğŸ†• è§¸ç™¼å‘é‡åº«é‡å»º
                try:
                    from core import reload_qa_system
                    reload_result = reload_qa_system()
                    result["vectordb_updated"] = reload_result
                    logger.info(f"âœ… å‘é‡åº«å·²æ›´æ–°: {output_name}")
                except Exception as e:
                    logger.error(f"å‘é‡åº«æ›´æ–°å¤±æ•—: {e}")
                    result["vectordb_updated"] = False
            else:
                # è½‰æ›å¤±æ•—ï¼Œä¿ç•™åŸæª”
                final_path = os.path.join(target_dir, safe_name)
                shutil.copy(temp_path, final_path)
                result["converted"] = False
                result["conversion_error"] = convert_result.get("error", "Unknown error")
                result["saved_as"] = safe_name
        else:
            # ç›´æ¥è¤‡è£½æª”æ¡ˆ
            final_path = os.path.join(target_dir, safe_name)
            shutil.copy(temp_path, final_path)
            result["saved_as"] = safe_name
            
            # ğŸ†• è§¸ç™¼å‘é‡åº«é‡å»ºï¼ˆå¦‚æœæ˜¯ markdown æˆ– txtï¼‰
            if ext in {'.md', '.txt', '.markdown'}:
                try:
                    from core import reload_qa_system
                    reload_result = reload_qa_system()
                    result["vectordb_updated"] = reload_result
                    logger.info(f"âœ… å‘é‡åº«å·²æ›´æ–°: {safe_name}")
                except Exception as e:
                    logger.error(f"å‘é‡åº«æ›´æ–°å¤±æ•—: {e}")
                    result["vectordb_updated"] = False
        
        return result
        
    finally:
        # æ¸…ç†æš«å­˜æª”
        if os.path.exists(temp_path):
            os.remove(temp_path)

@router.delete("/files/{filename}")
async def delete_file(filename: str, doc_type: str = "technical"):
    """åˆªé™¤çŸ¥è­˜åº«æ–‡ä»¶"""
    if doc_type == "business":
        target_dir = BUSINESS_DATA_DIR
    else:
        target_dir = DATA_DIR
    
    filepath = os.path.join(target_dir, filename)
    
    # å®‰å…¨æª¢æŸ¥
    if not os.path.abspath(filepath).startswith(os.path.abspath(target_dir)):
        raise HTTPException(status_code=403, detail="Access denied")
    
    if not os.path.exists(filepath):
        raise HTTPException(status_code=404, detail="File not found")
    
    try:
        os.remove(filepath)
        return {"success": True, "deleted": filename}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/stats")
async def get_knowledge_stats():
    """å–å¾—çŸ¥è­˜åº«çµ±è¨ˆè³‡è¨Š"""
    tech_files = 0
    tech_size = 0
    biz_files = 0
    biz_size = 0
    
    # æŠ€è¡“æ–‡æª”çµ±è¨ˆ
    if os.path.exists(DATA_DIR):
        for filename in os.listdir(DATA_DIR):
            filepath = os.path.join(DATA_DIR, filename)
            if os.path.isfile(filepath):
                tech_files += 1
                tech_size += os.path.getsize(filepath)
    
    # æ¥­å‹™è³‡æ–™çµ±è¨ˆ
    if os.path.exists(BUSINESS_DATA_DIR):
        for filename in os.listdir(BUSINESS_DATA_DIR):
            filepath = os.path.join(BUSINESS_DATA_DIR, filename)
            if os.path.isfile(filepath):
                biz_files += 1
                biz_size += os.path.getsize(filepath)
    
    return {
        "technical": {
            "files": tech_files,
            "size": tech_size,
            "size_mb": round(tech_size / 1024 / 1024, 2),
            "directory": DATA_DIR
        },
        "business": {
            "files": biz_files,
            "size": biz_size,
            "size_mb": round(biz_size / 1024 / 1024, 2),
            "directory": BUSINESS_DATA_DIR
        },
        "total_files": tech_files + biz_files,
        "total_size_mb": round((tech_size + biz_size) / 1024 / 1024, 2)
    }

@router.post("/convert")
async def convert_file(
    file: UploadFile = File(...),
    output_format: str = Form("markdown")
):
    """
    è½‰æ›æ–‡ä»¶æ ¼å¼ï¼ˆä¸å„²å­˜åˆ°çŸ¥è­˜åº«ï¼‰
    
    Parameters:
    - file: è¦è½‰æ›çš„æª”æ¡ˆ
    - output_format: è¼¸å‡ºæ ¼å¼ (markdown/txt)
    """
    if not file.filename:
        raise HTTPException(status_code=400, detail="No filename provided")
    
    ext = get_file_extension(file.filename)
    if ext not in {'.pdf', '.docx', '.doc', '.rtf'}:
        raise HTTPException(status_code=400, detail="Only PDF, DOCX, DOC, RTF can be converted")
    
    temp_input = os.path.join(tempfile.gettempdir(), f"input_{datetime.now().timestamp()}{ext}")
    temp_output = os.path.join(tempfile.gettempdir(), f"output_{datetime.now().timestamp()}.md")
    
    try:
        content = await file.read()
        with open(temp_input, 'wb') as f:
            f.write(content)
        
        if ext == '.pdf':
            result = convert_pdf_to_markdown(temp_input, temp_output)
        else:
            result = convert_docx_to_markdown(temp_input, temp_output)
        
        if result.get("success"):
            with open(temp_output, 'r', encoding='utf-8') as f:
                converted_content = f.read()
            
            return {
                "success": True,
                "original_name": file.filename,
                "content": converted_content,
                "info": result
            }
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "Conversion failed"))
    
    finally:
        if os.path.exists(temp_input):
            os.remove(temp_input)
        if os.path.exists(temp_output):
            os.remove(temp_output)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ¥­å‹™æ—¥å ±å°ˆç”¨ç«¯é»
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post("/upload-business")
async def upload_business_report(
    file: UploadFile = File(...),
    months_to_keep: int = Form(12),
    merge_existing: bool = Form(True),
    auto_reload: bool = Form(True)
):
    """
    ä¸Šå‚³ä¸¦è™•ç† Lotus Notes åŒ¯å‡ºçš„æ¥­å‹™æ—¥å ±
    
    Parameters:
    - file: Lotus Notes åŒ¯å‡ºçš„ TXT æª”æ¡ˆ
    - months_to_keep: ä¿ç•™æœ€è¿‘å¹¾å€‹æœˆçš„è³‡æ–™ï¼ˆé è¨­ 12 å€‹æœˆï¼‰
    - merge_existing: æ˜¯å¦èˆ‡ç¾æœ‰è³‡æ–™åˆä½µï¼ˆå¢é‡æ›´æ–°ï¼‰
    - auto_reload: è™•ç†å®Œæˆå¾Œæ˜¯å¦è‡ªå‹•é‡å»ºå‘é‡ç´¢å¼•
    
    Returns:
    - è™•ç†çµ±è¨ˆè³‡è¨Š
    """
    if not file.filename:
        raise HTTPException(status_code=400, detail="No filename provided")
    
    ext = get_file_extension(file.filename)
    if ext != '.txt':
        raise HTTPException(status_code=400, detail="Only TXT files from Lotus Notes are supported")
    
    # å„²å­˜ä¸Šå‚³çš„æª”æ¡ˆ
    temp_path = os.path.join(tempfile.gettempdir(), f"business_{datetime.now().timestamp()}.txt")
    
    try:
        content = await file.read()
        with open(temp_path, 'wb') as f:
            f.write(content)
        
        # ä½¿ç”¨æ¥­å‹™è™•ç†å™¨
        try:
            from business_processor import process_and_update_knowledge_base
            
            result = process_and_update_knowledge_base(
                input_path=temp_path,
                business_dir=BUSINESS_DATA_DIR,
                months_to_keep=months_to_keep,
                trigger_reload=auto_reload
            )
            
            return {
                "success": True,
                "message": "æ¥­å‹™æ—¥å ±è™•ç†å®Œæˆ",
                "original_file": file.filename,
                "months_kept": months_to_keep,
                "stats": result.get("stats", {}),
                "csv_path": result.get("csv_path"),
                "reloaded": result.get("reloaded", False)
            }
            
        except ImportError:
            # é€€è·¯ï¼šä½¿ç”¨ç°¡åŒ–ç‰ˆè™•ç†
            return await _fallback_business_processing(temp_path, months_to_keep, merge_existing)
    
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)


async def _fallback_business_processing(
    temp_path: str, 
    months_to_keep: int,
    merge_existing: bool
) -> Dict[str, Any]:
    """ç°¡åŒ–ç‰ˆæ¥­å‹™æ—¥å ±è™•ç†ï¼ˆç•¶ business_processor ä¸å¯ç”¨æ™‚ï¼‰"""
    import re
    from datetime import datetime
    from dateutil.relativedelta import relativedelta
    
    # è®€å–æª”æ¡ˆ
    text = None
    for enc in ("utf-8", "utf-8-sig", "cp950", "big5"):
        try:
            with open(temp_path, 'r', encoding=enc, errors='ignore') as f:
                text = f.read()
            break
        except:
            continue
    
    if not text:
        raise HTTPException(status_code=400, detail="ç„¡æ³•è®€å–æª”æ¡ˆ")
    
    # è¨ˆç®—æˆªæ­¢æ—¥æœŸ
    cutoff = datetime.now() - relativedelta(months=months_to_keep)
    cutoff_str = cutoff.strftime("%Y/%m/%d")
    
    # ç°¡å–®çµ±è¨ˆ
    date_pattern = re.compile(r"Date:\s*(\d{4}/\d{1,2}/\d{1,2})")
    dates = date_pattern.findall(text)
    
    total = len(dates)
    filtered = sum(1 for d in dates if d >= cutoff_str)
    
    return {
        "success": True,
        "message": "ä½¿ç”¨ç°¡åŒ–ç‰ˆè™•ç†ï¼ˆå»ºè­°å®‰è£ business_processor.pyï¼‰",
        "stats": {
            "raw_records": total,
            "after_filter": filtered,
            "cutoff_date": cutoff_str
        },
        "note": "è«‹æ‰‹å‹•åŸ·è¡Œ clean_business.py é€²è¡Œå®Œæ•´è™•ç†"
    }


@router.get("/business-config")
async def get_business_config():
    """å–å¾—æ¥­å‹™è³‡æ–™è™•ç†è¨­å®š"""
    csv_path = os.path.join(BUSINESS_DATA_DIR, "clean_business.csv")
    
    config = {
        "business_dir": BUSINESS_DATA_DIR,
        "csv_exists": os.path.exists(csv_path),
        "default_months_to_keep": 12,
        "supported_formats": [".txt"],
        "auto_reload_available": True
    }
    
    # å¦‚æœ CSV å­˜åœ¨ï¼Œæä¾›çµ±è¨ˆè³‡è¨Š
    if config["csv_exists"]:
        try:
            import pandas as pd
            df = pd.read_csv(csv_path, encoding="utf-8-sig")
            config["current_records"] = len(df)
            
            if "Date" in df.columns:
                dates = df["Date"].dropna()
                if len(dates) > 0:
                    config["date_range"] = {
                        "min": dates.min(),
                        "max": dates.max()
                    }
            
            if "Worker" in df.columns:
                config["workers"] = df["Worker"].nunique()
        except:
            pass
    
    return config

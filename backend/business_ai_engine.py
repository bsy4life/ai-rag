# business_ai_engine.py - ç´” AI é©…å‹•çš„æ¥­å‹™æ™ºèƒ½æŸ¥è©¢å¼•æ“
"""
åŠŸèƒ½ï¼š
1. AI æ„åœ–è§£æ - ä¸å†ç¡¬ç·¨ç¢¼è¦å‰‡ï¼Œç”± LLM ç†è§£æŸ¥è©¢æ„åœ–
2. å‹•æ…‹ä»£ç¢¼ç”Ÿæˆ - AI ç”Ÿæˆ Pandas æŸ¥è©¢ä»£ç¢¼
3. BI åˆ†æå±¤ - è¶¨å‹¢åˆ†æã€ç•°å¸¸åµæ¸¬ã€æ™ºèƒ½å»ºè­°
4. è‡ªç„¶èªè¨€å›è¦† - å°‡æ•¸æ“šè½‰ç‚ºäººé¡æ˜“è®€çš„æ´å¯Ÿ

ä½¿ç”¨æ–¹å¼ï¼š
    from business_ai_engine import BusinessAIEngine
    
    engine = BusinessAIEngine()
    result = engine.query("å°å—ç‡Ÿæ¥­æ‰€æœ€è¿‘ä¸€å€‹æœˆçš„æ¥­ç¸¾å¦‚ä½•ï¼Ÿæœ‰ä»€éº¼å€¼å¾—æ³¨æ„çš„è¶¨å‹¢ï¼Ÿ")
    print(result['answer'])
"""

import os
import re
import json
import logging
import traceback
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass, field, asdict
from enum import Enum

logger = logging.getLogger(__name__)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¾è³´æª¢æŸ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

try:
    import pandas as pd
    _HAS_PANDAS = True
except ImportError:
    _HAS_PANDAS = False
    logger.warning("pandas æœªå®‰è£ï¼Œæ¥­å‹™ AI å¼•æ“å°‡ç„¡æ³•é‹ä½œ")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ•¸æ“šçµæ§‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class QueryIntent(Enum):
    """æŸ¥è©¢æ„åœ–é¡å‹"""
    AGGREGATE = "aggregate"      # èšåˆçµ±è¨ˆï¼ˆç¸½æ•¸ã€å¹³å‡ç­‰ï¼‰
    LIST = "list"                # åˆ—å‡ºæ˜ç´°
    TREND = "trend"              # è¶¨å‹¢åˆ†æ
    COMPARE = "compare"          # æ¯”è¼ƒåˆ†æ
    ANOMALY = "anomaly"          # ç•°å¸¸åµæ¸¬
    FORECAST = "forecast"        # é æ¸¬
    RANKING = "ranking"          # æ’å
    SEARCH = "search"            # æœå°‹ç‰¹å®šè¨˜éŒ„


@dataclass
class ParsedIntent:
    """è§£æå¾Œçš„æŸ¥è©¢æ„åœ–"""
    intent: QueryIntent
    time_range: Optional[Dict] = None      # {"start": date, "end": date}
    filters: Dict = field(default_factory=dict)  # {"branch": "å°å—ç‡Ÿæ¥­æ‰€", "worker": "å¼µä¸‰"}
    metrics: List[str] = field(default_factory=list)  # ["æ‹œè¨ªæ¬¡æ•¸", "å®¢æˆ¶æ•¸"]
    group_by: List[str] = field(default_factory=list)  # ["Worker", "Customer"]
    sort_by: Optional[str] = None
    limit: Optional[int] = None
    raw_query: str = ""


@dataclass
class AnalysisResult:
    """åˆ†æçµæœ"""
    answer: str                           # è‡ªç„¶èªè¨€å›ç­”
    data_summary: Dict                    # æ•¸æ“šæ‘˜è¦
    insights: List[str]                   # BI æ´å¯Ÿ
    recommendations: List[str]            # å»ºè­°è¡Œå‹•
    visualizations: List[Dict] = field(default_factory=list)  # åœ–è¡¨å»ºè­°
    raw_data: Optional[Any] = None        # åŸå§‹æ•¸æ“šï¼ˆå¯é¸ï¼‰
    code_executed: str = ""               # åŸ·è¡Œçš„ä»£ç¢¼
    metadata: Dict = field(default_factory=dict)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Schema å®šç¾©ï¼ˆè®“ AI ç†è§£æ•¸æ“šçµæ§‹ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BUSINESS_DATA_SCHEMA = """
æ¥­å‹™æ—¥å ± CSV æ•¸æ“šçµæ§‹ï¼š

æ¬„ä½èªªæ˜ï¼š
- Date: æ—¥æœŸ (æ ¼å¼: YYYY/MM/DD)
- Worker: æ¥­å‹™å“¡å§“å
- Customer: å®¢æˆ¶åç¨±
- Class: æ´»å‹•é¡å‹ (å¦‚: æ¥­å‹™æ‹œè¨ª, é€è²¨, å ±åƒ¹, é›»è©±è¯ç¹«, æœƒè­°, ç¶­ä¿®æœå‹™)
- Content: æ´»å‹•å…§å®¹æè¿°
- Depart: ç‡Ÿæ¥­æ‰€ (å¦‚: å°å—ç‡Ÿæ¥­æ‰€, å°ä¸­ç‡Ÿæ¥­æ‰€, é«˜é›„ç‡Ÿæ¥­æ‰€, å°åŒ—ç‡Ÿæ¥­æ‰€)
- Manager: ä¸»ç®¡å§“å
- Level: ç­‰ç´š
- Doc_Status: æ–‡ä»¶ç‹€æ…‹
- TimeCreated: å»ºç«‹æ™‚é–“
- Doc_Time: æ–‡ä»¶æ™‚é–“

åŸ·è¡Œç’°å¢ƒå·²æä¾›çš„è®Šæ•¸ï¼ˆä¸éœ€è¦ importï¼‰ï¼š
- df: æ¥­å‹™æ•¸æ“š DataFrame
- pd: pandas æ¨¡çµ„
- datetime: datetime é¡åˆ¥  
- timedelta: timedelta é¡åˆ¥
- re: æ­£å‰‡è¡¨é”å¼æ¨¡çµ„

å¸¸è¦‹æŸ¥è©¢æ¨¡å¼ï¼š
1. æ™‚é–“ç¯„åœéæ¿¾: df[df['_Date'] >= start_date]
2. ç‡Ÿæ¥­æ‰€éæ¿¾: df[df['Depart'].str.contains('å°å—')]
3. æ¥­å‹™å“¡éæ¿¾: df[df['Worker'] == 'å¼µä¸‰']
4. å®¢æˆ¶éæ¿¾: df[df['Customer'].str.contains('æ±å°')]
5. æ´»å‹•é¡å‹éæ¿¾: df[df['Class'].str.contains('æ¥­å‹™æ‹œè¨ª')]

é‡è¦æé†’ï¼š
- æ—¥æœŸæ¬„ä½ '_Date' æ˜¯ datetime é¡å‹ï¼Œå·²ç¶“åœ¨æ•¸æ“šé è™•ç†æ™‚å»ºç«‹
- ä½¿ç”¨ .str.contains() é€²è¡Œæ¨¡ç³ŠåŒ¹é…
- ä½¿ç”¨ pd.Timestamp è™•ç†æ—¥æœŸæ¯”è¼ƒ
- ä¸è¦ä½¿ç”¨ import èªå¥ï¼
"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Prompt æ¨¡æ¿
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INTENT_PARSING_PROMPT = """ä½ æ˜¯ä¸€å€‹æ¥­å‹™æ•¸æ“šåˆ†æåŠ©æ‰‹ã€‚è«‹åˆ†æç”¨æˆ¶çš„æŸ¥è©¢æ„åœ–ï¼Œä¸¦æå–é—œéµä¿¡æ¯ã€‚

ç”¨æˆ¶æŸ¥è©¢ï¼š{query}

ç•¶å‰æ—¥æœŸï¼š{today}

è«‹ä»¥ JSON æ ¼å¼å›ç­”ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
{{
    "intent": "aggregate|list|trend|compare|anomaly|ranking|search",
    "time_range": {{
        "type": "relative|absolute|none",
        "value": "æœ€è¿‘30å¤©|2024å¹´1æœˆ|2024/01/01-2024/01/31",
        "start": "YYYY-MM-DD æˆ– null",
        "end": "YYYY-MM-DD æˆ– null"
    }},
    "filters": {{
        "branch": "ç‡Ÿæ¥­æ‰€åç¨±æˆ–null",
        "worker": "æ¥­å‹™å“¡åç¨±æˆ–null",
        "customer": "å®¢æˆ¶åç¨±æˆ–null",
        "activity_type": "æ´»å‹•é¡å‹æˆ–null"
    }},
    "metrics": ["è¦è¨ˆç®—çš„æŒ‡æ¨™ï¼Œå¦‚æ‹œè¨ªæ¬¡æ•¸ã€å®¢æˆ¶æ•¸ç­‰"],
    "group_by": ["åˆ†çµ„æ¬„ä½ï¼Œå¦‚Workerã€Customerã€Departç­‰"],
    "analysis_focus": "ç”¨æˆ¶é—œæ³¨çš„åˆ†æé‡é»æè¿°"
}}

åªå›ç­” JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚"""


CODE_GENERATION_PROMPT = """ä½ æ˜¯ä¸€å€‹ Python/Pandas å°ˆå®¶ã€‚è«‹æ ¹æ“šç”¨æˆ¶æ„åœ–ç”ŸæˆæŸ¥è©¢ä»£ç¢¼ã€‚

{schema}

ç”¨æˆ¶æŸ¥è©¢ï¼š{query}
è§£æå¾Œçš„æ„åœ–ï¼š{intent_json}
ç•¶å‰æ—¥æœŸï¼š{today}

è«‹ç”Ÿæˆ Python ä»£ç¢¼ï¼Œä½¿ç”¨è®Šæ•¸ `df` ä½œç‚ºè¼¸å…¥ DataFrameã€‚

ã€é‡è¦é™åˆ¶ã€‘
1. ä¸è¦ä½¿ç”¨ import èªå¥ï¼ä»¥ä¸‹è®Šæ•¸å·²å¯ç”¨ï¼šdf, pd, datetime, timedelta, re
2. å¿…é ˆæŒ‰ç…§ä»¥ä¸‹é †åºç·¨å¯«ä»£ç¢¼ï¼š
   - ç¬¬ä¸€æ­¥ï¼šå»ºç«‹éæ¿¾æ¢ä»¶ mask
   - ç¬¬äºŒæ­¥ï¼šéæ¿¾æ•¸æ“šå¾—åˆ° filtered = df[mask]
   - ç¬¬ä¸‰æ­¥ï¼šåŸºæ–¼ filtered é€²è¡Œçµ±è¨ˆåˆ†æï¼Œå­˜å…¥ result
   - ç¬¬å››æ­¥ï¼šå»ºç«‹ summary å­—å…¸
3. æ‰€æœ‰å° filtered çš„å¼•ç”¨å¿…é ˆåœ¨ filtered = df[mask] ä¹‹å¾Œ

ã€ä»£ç¢¼æ¨¡æ¿ - å¿…é ˆéµå¾ªæ­¤çµæ§‹ã€‘
```python
# ç¬¬ä¸€æ­¥ï¼šå»ºç«‹éæ¿¾æ¢ä»¶
mask = pd.Series([True] * len(df))

# æ™‚é–“éæ¿¾ï¼ˆæ ¹æ“šéœ€è¦èª¿æ•´æ—¥æœŸï¼‰
mask = mask & (df['_Date'] >= pd.Timestamp('2024-10-01'))
mask = mask & (df['_Date'] <= pd.Timestamp('2024-10-31'))

# å…¶ä»–éæ¿¾ï¼ˆå®¢æˆ¶ã€æ¥­å‹™å“¡ç­‰ï¼‰
mask = mask & (df['Customer'].str.contains('å°å¡‘', na=False))

# ç¬¬äºŒæ­¥ï¼šåŸ·è¡Œéæ¿¾
filtered = df[mask]

# ç¬¬ä¸‰æ­¥ï¼šçµ±è¨ˆåˆ†æï¼ˆå¿…é ˆåœ¨ filtered å®šç¾©ä¹‹å¾Œï¼‰
result = filtered[['Date', 'Worker', 'Customer', 'Class', 'Content']].copy()

# æˆ–è€…åšåˆ†çµ„çµ±è¨ˆ
# result = filtered.groupby('Worker').agg({{
#     'Customer': 'nunique',
#     'Date': 'count'
# }})

# ç¬¬å››æ­¥ï¼šå»ºç«‹æ‘˜è¦
summary = {{
    'total_records': len(filtered),
    'unique_workers': filtered['Worker'].nunique() if len(filtered) > 0 else 0,
    'unique_customers': filtered['Customer'].nunique() if len(filtered) > 0 else 0
}}
```

åªè¼¸å‡ºå¯åŸ·è¡Œçš„ Python ä»£ç¢¼ï¼Œä¸è¦æœ‰ markdown æ¨™è¨˜ï¼Œä¸è¦æœ‰ import èªå¥ã€‚
ç¢ºä¿ filtered è®Šæ•¸åœ¨è¢«å¼•ç”¨å‰å·²ç¶“å®šç¾©ï¼"""


ANALYSIS_PROMPT = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ¥­å‹™åˆ†æé¡§å•ã€‚è«‹æ ¹æ“šæŸ¥è©¢çµæœæä¾›æ·±å…¥çš„ BI åˆ†æã€‚

åŸå§‹æŸ¥è©¢ï¼š{query}
æ•¸æ“šæ‘˜è¦ï¼š{summary}
è©³ç´°çµæœï¼š{result_preview}

è«‹æä¾›ï¼š
1. **ç›´æ¥å›ç­”**ï¼šç”¨è‡ªç„¶èªè¨€å›ç­”ç”¨æˆ¶çš„å•é¡Œï¼ˆ2-3 å¥è©±ï¼‰
2. **é—œéµæ´å¯Ÿ**ï¼šå¾æ•¸æ“šä¸­ç™¼ç¾çš„ 3-5 å€‹é‡è¦ç™¼ç¾
3. **è¶¨å‹¢åˆ†æ**ï¼šå¦‚æœæ•¸æ“šæ¶‰åŠæ™‚é–“ï¼Œåˆ†æè®ŠåŒ–è¶¨å‹¢
4. **ç•°å¸¸åµæ¸¬**ï¼šæ¨™å‡ºä»»ä½•ç•°å¸¸æˆ–å€¼å¾—æ³¨æ„çš„æ•¸æ“šé»
5. **å»ºè­°è¡Œå‹•**ï¼šåŸºæ–¼åˆ†æçµæœï¼Œæå‡º 2-3 å€‹å…·é«”çš„è¡Œå‹•å»ºè­°

è«‹ä»¥ JSON æ ¼å¼å›ç­”ï¼š
{{
    "direct_answer": "ç›´æ¥å›ç­”ç”¨æˆ¶å•é¡Œ...",
    "insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2", "æ´å¯Ÿ3"],
    "trends": ["è¶¨å‹¢æè¿°1", "è¶¨å‹¢æè¿°2"],
    "anomalies": ["ç•°å¸¸1", "ç•°å¸¸2"],
    "recommendations": ["å»ºè­°1", "å»ºè­°2", "å»ºè­°3"],
    "visualization_suggestions": [
        {{"type": "bar", "title": "åœ–è¡¨æ¨™é¡Œ", "x": "æ¬„ä½", "y": "æ¬„ä½"}},
        {{"type": "line", "title": "è¶¨å‹¢åœ–", "x": "Date", "y": "count"}}
    ]
}}

åªå›ç­” JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LLM å®¢æˆ¶ç«¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LLMClient:
    """LLM å®¢æˆ¶ç«¯ï¼ˆæ”¯æ´ OpenAI å’Œ Anthropicï¼‰"""
    
    def __init__(self):
        self.provider = os.getenv("LLM_PROVIDER", "openai").strip().lower()
        self.openai_key = os.getenv("OPENAI_API_KEY", "")
        self.anthropic_key = os.getenv("ANTHROPIC_API_KEY", "")
        
        # è™•ç† auto æ¨¡å¼ï¼šæ ¹æ“š LLM_PRIMARY æ±ºå®šå„ªå…ˆä½¿ç”¨å“ªå€‹
        if self.provider == "auto":
            primary = os.getenv("LLM_PRIMARY", "anthropic").strip().lower()
            if primary in ("anthropic", "claude"):
                self.provider = "anthropic"
            else:
                self.provider = "openai"
            logger.info(f"ğŸ”„ Auto æ¨¡å¼ï¼Œé¸æ“‡ primary: {self.provider}")
        
        # æ¥­å‹™åˆ†æå°ˆç”¨æ¨¡å‹
        self.model = os.getenv("LLM_MODEL_BUSINESS", "gpt-4o")
        
        self._client = None
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ–å®¢æˆ¶ç«¯"""
        if self.provider in ("anthropic", "claude") and self.anthropic_key:
            try:
                from anthropic import Anthropic
                self._client = Anthropic(api_key=self.anthropic_key)
                self.provider = "anthropic"
                self.model = os.getenv("ANTHROPIC_MODEL_BUSINESS", "claude-sonnet-4-20250514")
                logger.info(f"âœ… æ¥­å‹™ AI å¼•æ“ä½¿ç”¨ Anthropic: {self.model}")
            except ImportError:
                logger.warning("anthropic å¥—ä»¶æœªå®‰è£ï¼Œé™ç´šåˆ° OpenAI")
                self._init_openai()
        else:
            self._init_openai()
    
    def _init_openai(self):
        """åˆå§‹åŒ– OpenAI"""
        if self.openai_key:
            try:
                from openai import OpenAI
                self._client = OpenAI(api_key=self.openai_key)
                self.provider = "openai"
                self.model = os.getenv("OPENAI_MODEL_BUSINESS", "gpt-4o")
                logger.info(f"âœ… æ¥­å‹™ AI å¼•æ“ä½¿ç”¨ OpenAI: {self.model}")
            except ImportError:
                raise RuntimeError("éœ€è¦å®‰è£ openai æˆ– anthropic å¥—ä»¶")
    
    def chat(self, prompt: str, system: str = None, temperature: float = 0.1) -> str:
        """ç™¼é€èŠå¤©è«‹æ±‚ï¼ˆå¸¶ fallbackï¼‰"""
        try:
            if self.provider == "anthropic":
                return self._chat_anthropic(prompt, system, temperature)
            else:
                return self._chat_openai(prompt, system, temperature)
        except Exception as e:
            error_msg = str(e)
            # æª¢æŸ¥æ˜¯å¦æ˜¯é™é¡éŒ¯èª¤
            if "usage limits" in error_msg or "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
                logger.warning(f"âš ï¸ {self.provider} é™é¡ï¼Œå˜—è©¦ fallback: {e}")
                return self._fallback_chat(prompt, system, temperature)
            else:
                raise
    
    def _fallback_chat(self, prompt: str, system: str = None, temperature: float = 0.1) -> str:
        """Fallback åˆ°å¦ä¸€å€‹æä¾›å•†"""
        if self.provider == "anthropic" and self.openai_key:
            # Fallback åˆ° OpenAI
            try:
                from openai import OpenAI
                fallback_client = OpenAI(api_key=self.openai_key)
                fallback_model = os.getenv("OPENAI_MODEL_BUSINESS", "gpt-4o")
                
                messages = []
                if system:
                    messages.append({"role": "system", "content": system})
                messages.append({"role": "user", "content": prompt})
                
                logger.info(f"ğŸ”„ Fallback åˆ° OpenAI: {fallback_model}")
                response = fallback_client.chat.completions.create(
                    model=fallback_model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=4000,
                )
                logger.info("âœ… Fallback æˆåŠŸ")
                return response.choices[0].message.content
            except Exception as e:
                logger.error(f"âŒ Fallback åˆ° OpenAI ä¹Ÿå¤±æ•—: {e}")
                raise
        elif self.provider == "openai" and self.anthropic_key:
            # Fallback åˆ° Anthropic
            try:
                from anthropic import Anthropic
                fallback_client = Anthropic(api_key=self.anthropic_key)
                fallback_model = os.getenv("ANTHROPIC_MODEL_BUSINESS", "claude-sonnet-4-20250514")
                
                kwargs = {
                    "model": fallback_model,
                    "max_tokens": 4000,
                    "messages": [{"role": "user", "content": prompt}],
                }
                if system:
                    kwargs["system"] = system
                
                logger.info(f"ğŸ”„ Fallback åˆ° Anthropic: {fallback_model}")
                response = fallback_client.messages.create(**kwargs)
                logger.info("âœ… Fallback æˆåŠŸ")
                return response.content[0].text
            except Exception as e:
                logger.error(f"âŒ Fallback åˆ° Anthropic ä¹Ÿå¤±æ•—: {e}")
                raise
        else:
            raise RuntimeError("ç„¡å¯ç”¨çš„ fallback æä¾›å•†")
    
    def _chat_openai(self, prompt: str, system: str = None, temperature: float = 0.1) -> str:
        """OpenAI èŠå¤©ï¼ˆæ”¯æ´ o ç³»åˆ—æ¨ç†æ¨¡å‹ï¼‰"""
        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        messages.append({"role": "user", "content": prompt})
        
        # æª¢æ¸¬æ˜¯å¦ç‚º o ç³»åˆ—æ¨¡å‹ï¼ˆo1, o3, gpt-5 ç­‰ï¼‰
        # é€™äº›æ¨¡å‹ä¸æ”¯æ´ max_tokensï¼Œè¦ç”¨ max_completion_tokens
        # ä¹Ÿä¸æ”¯æ´ temperature åƒæ•¸
        model_lower = self.model.lower()
        is_reasoning_model = any(x in model_lower for x in ['o1', 'o3', 'gpt-5', 'o4'])
        
        if is_reasoning_model:
            # o ç³»åˆ—æ¨¡å‹çš„åƒæ•¸
            response = self._client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_completion_tokens=4000,
                # o ç³»åˆ—ä¸æ”¯æ´ temperature
            )
        else:
            # æ¨™æº–æ¨¡å‹çš„åƒæ•¸
            response = self._client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=4000,
            )
        return response.choices[0].message.content
    
    def _chat_anthropic(self, prompt: str, system: str = None, temperature: float = 0.1) -> str:
        """Anthropic èŠå¤©"""
        kwargs = {
            "model": self.model,
            "max_tokens": 4000,
            "messages": [{"role": "user", "content": prompt}],
        }
        if system:
            kwargs["system"] = system
        
        response = self._client.messages.create(**kwargs)
        return response.content[0].text


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ¥­å‹™ AI å¼•æ“
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BusinessAIEngine:
    """ç´” AI é©…å‹•çš„æ¥­å‹™æ™ºèƒ½æŸ¥è©¢å¼•æ“"""
    
    def __init__(self, csv_path: str = None):
        """
        åˆå§‹åŒ–å¼•æ“
        
        Args:
            csv_path: æ¥­å‹™ CSV æª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼Œæœƒè‡ªå‹•åµæ¸¬ï¼‰
        """
        if not _HAS_PANDAS:
            raise RuntimeError("éœ€è¦å®‰è£ pandas: pip install pandas")
        
        self.csv_path = csv_path or self._detect_csv_path()
        self.llm = LLMClient()
        self.df = None
        self._load_data()
    
    def _detect_csv_path(self) -> Optional[str]:
        """è‡ªå‹•åµæ¸¬ CSV è·¯å¾‘"""
        candidates = [
            os.environ.get("BUSINESS_CSV_FILE"),
            "/app/data/business/clean_business.csv",
            "./data/business/clean_business.csv",
            "./business/clean_business.csv",
            "clean_business.csv",
        ]
        for p in candidates:
            if p and os.path.exists(p):
                return p
        return None
    
    def _load_data(self):
        """è¼‰å…¥ä¸¦é è™•ç†æ•¸æ“š"""
        if not self.csv_path or not os.path.exists(self.csv_path):
            logger.warning(f"æ¥­å‹™ CSV ä¸å­˜åœ¨: {self.csv_path}")
            return
        
        try:
            self.df = pd.read_csv(self.csv_path, encoding='utf-8')
            self.df = self.df.dropna(how='all')
            
            # é è™•ç†æ—¥æœŸ
            self.df['_Date'] = pd.to_datetime(self.df['Date'], errors='coerce')
            
            # æ¸…ç†ç©ºå€¼
            for col in ['Worker', 'Customer', 'Class', 'Depart', 'Content']:
                if col in self.df.columns:
                    self.df[col] = self.df[col].fillna('').astype(str)
            
            logger.info(f"âœ… è¼‰å…¥æ¥­å‹™æ•¸æ“š: {len(self.df)} ç­†è¨˜éŒ„")
        except Exception as e:
            logger.error(f"è¼‰å…¥æ¥­å‹™æ•¸æ“šå¤±æ•—: {e}")
            self.df = None
    
    def reload_data(self):
        """é‡æ–°è¼‰å…¥æ•¸æ“š"""
        self._load_data()
    
    def _parse_intent(self, query: str) -> Dict:
        """ä½¿ç”¨ AI è§£ææŸ¥è©¢æ„åœ–"""
        prompt = INTENT_PARSING_PROMPT.format(
            query=query,
            today=datetime.now().strftime("%Y-%m-%d")
        )
        
        try:
            response = self.llm.chat(prompt, temperature=0.0)
            # æ¸…ç† markdown æ¨™è¨˜
            response = response.strip()
            if response.startswith("```"):
                response = re.sub(r'^```\w*\n?', '', response)
                response = re.sub(r'\n?```$', '', response)
            
            return json.loads(response)
        except json.JSONDecodeError as e:
            logger.warning(f"æ„åœ–è§£æ JSON éŒ¯èª¤: {e}, åŸå§‹å›æ‡‰: {response[:500]}")
            return {"intent": "search", "filters": {}, "metrics": []}
        except Exception as e:
            logger.error(f"æ„åœ–è§£æå¤±æ•—: {e}")
            return {"intent": "search", "filters": {}, "metrics": []}
    
    def _generate_code(self, query: str, intent: Dict) -> str:
        """ä½¿ç”¨ AI ç”ŸæˆæŸ¥è©¢ä»£ç¢¼"""
        prompt = CODE_GENERATION_PROMPT.format(
            schema=BUSINESS_DATA_SCHEMA,
            query=query,
            intent_json=json.dumps(intent, ensure_ascii=False, indent=2),
            today=datetime.now().strftime("%Y-%m-%d")
        )
        
        try:
            response = self.llm.chat(prompt, temperature=0.0)
            
            # æ¸…ç† markdown æ¨™è¨˜
            code = response.strip()
            if code.startswith("```"):
                code = re.sub(r'^```\w*\n?', '', code)
                code = re.sub(r'\n?```$', '', code)
            
            return code
        except Exception as e:
            logger.error(f"ä»£ç¢¼ç”Ÿæˆå¤±æ•—: {e}")
            return ""
    
    def _preprocess_code(self, code: str) -> str:
        """
        é è™•ç† AI ç”Ÿæˆçš„ä»£ç¢¼ï¼Œä¿®å¾©å¸¸è¦‹å•é¡Œ
        """
        if not code:
            return code
        
        # 1. ç§»é™¤ markdown ä»£ç¢¼å¡Šæ¨™è¨˜
        code = re.sub(r'^```\w*\n?', '', code.strip())
        code = re.sub(r'\n?```$', '', code)
        
        # 2. ç§»é™¤ import èªå¥ï¼ˆæˆ‘å€‘å·²ç¶“æä¾›äº†æ‰€éœ€æ¨¡çµ„ï¼‰
        lines = code.split('\n')
        cleaned_lines = []
        for line in lines:
            stripped = line.strip()
            if stripped.startswith('import ') or stripped.startswith('from '):
                logger.debug(f"ç§»é™¤ import èªå¥: {stripped}")
                continue
            cleaned_lines.append(line)
        code = '\n'.join(cleaned_lines)
        
        # 3. ä¿®å¾©æ‹¬è™Ÿä¸åŒ¹é…å•é¡Œ
        code = self._fix_brackets(code)
        
        return code
    
    def _fix_brackets(self, code: str) -> str:
        """
        ä¿®å¾©æ‹¬è™Ÿä¸åŒ¹é…å•é¡Œ
        """
        # è¨ˆç®—å„é¡æ‹¬è™Ÿçš„æ•¸é‡
        open_parens = code.count('(')
        close_parens = code.count(')')
        open_brackets = code.count('[')
        close_brackets = code.count(']')
        open_braces = code.count('{')
        close_braces = code.count('}')
        
        # è£œé½Šç¼ºå°‘çš„å³æ‹¬è™Ÿ
        if open_parens > close_parens:
            missing = open_parens - close_parens
            code = code.rstrip() + ')' * missing
            logger.debug(f"è£œé½Š {missing} å€‹å³å°æ‹¬è™Ÿ")
        
        if open_brackets > close_brackets:
            missing = open_brackets - close_brackets
            code = code.rstrip() + ']' * missing
            logger.debug(f"è£œé½Š {missing} å€‹å³ä¸­æ‹¬è™Ÿ")
        
        if open_braces > close_braces:
            missing = open_braces - close_braces
            code = code.rstrip() + '}' * missing
            logger.debug(f"è£œé½Š {missing} å€‹å³å¤§æ‹¬è™Ÿ")
        
        return code
    
    def _execute_code(self, code: str) -> Tuple[Any, Dict, str]:
        """
        å®‰å…¨åŸ·è¡Œç”Ÿæˆçš„ä»£ç¢¼
        
        Returns:
            (result, summary, error_message)
        """
        if self.df is None or self.df.empty:
            return None, {}, "æ•¸æ“šæœªè¼‰å…¥"
        
        # æº–å‚™å®‰å…¨çš„å…§å»ºå‡½æ•¸å­é›†
        safe_builtins = {
            'len': len,
            'str': str,
            'int': int,
            'float': float,
            'bool': bool,
            'list': list,
            'dict': dict,
            'tuple': tuple,
            'set': set,
            'range': range,
            'enumerate': enumerate,
            'zip': zip,
            'map': map,
            'filter': filter,
            'sorted': sorted,
            'sum': sum,
            'min': min,
            'max': max,
            'abs': abs,
            'round': round,
            'any': any,
            'all': all,
            'isinstance': isinstance,
            'hasattr': hasattr,
            'getattr': getattr,
            'print': print,  # ç”¨æ–¼èª¿è©¦
            'True': True,
            'False': False,
            'None': None,
        }
        
        # æº–å‚™åŸ·è¡Œç’°å¢ƒ
        local_vars = {
            'df': self.df.copy(),
            'pd': pd,
            'datetime': datetime,
            'timedelta': timedelta,
            're': re,  # æ­£å‰‡è¡¨é”å¼
        }
        
        # é è™•ç†ä»£ç¢¼ï¼šæ¸…ç†å’Œä¿®å¾©å¸¸è¦‹å•é¡Œ
        code = self._preprocess_code(code)
        
        try:
            exec(code, {"__builtins__": safe_builtins}, local_vars)
            
            result = local_vars.get('result', local_vars.get('filtered', None))
            summary = local_vars.get('summary', {})
            
            # å¦‚æœæ²’æœ‰ summaryï¼Œè‡ªå‹•ç”Ÿæˆ
            if not summary and result is not None:
                if isinstance(result, pd.DataFrame):
                    summary = {
                        'total_records': len(result),
                        'columns': list(result.columns),
                    }
                elif isinstance(result, pd.Series):
                    summary = {
                        'total_items': len(result),
                        'top_values': result.head(5).to_dict(),
                    }
            
            return result, summary, ""
            
        except Exception as e:
            error_msg = f"ä»£ç¢¼åŸ·è¡ŒéŒ¯èª¤: {str(e)}\n{traceback.format_exc()}"
            logger.error(error_msg)
            return None, {}, error_msg
    
    def _fallback_query(self, query: str, intent: Dict) -> Tuple[Any, Dict, str]:
        """
        ç•¶ AI ç”Ÿæˆä»£ç¢¼å¤±æ•—æ™‚çš„ fallback æŸ¥è©¢
        åŸºæ–¼ intent ä¸­çš„é—œéµä¿¡æ¯é€²è¡Œç°¡å–®éæ¿¾
        """
        try:
            df = self.df.copy()
            mask = pd.Series([True] * len(df))
            
            filters = intent.get("filters", {})
            time_range = intent.get("time_range", {})
            
            # æ™‚é–“éæ¿¾
            if time_range.get("start"):
                try:
                    start = pd.Timestamp(time_range["start"])
                    mask = mask & (df['_Date'] >= start)
                except:
                    pass
            
            if time_range.get("end"):
                try:
                    end = pd.Timestamp(time_range["end"])
                    mask = mask & (df['_Date'] <= end)
                except:
                    pass
            
            # æ ¹æ“šæœˆä»½éæ¿¾ï¼ˆå¾ time_range.value æå–ï¼‰
            time_value = time_range.get("value", "")
            if "æœˆ" in str(time_value):
                month_match = re.search(r'(\d+)\s*æœˆ', str(time_value))
                if month_match:
                    month = int(month_match.group(1))
                    year = datetime.now().year
                    # å¦‚æœæåˆ°çš„æœˆä»½å¤§æ–¼ç•¶å‰æœˆä»½ï¼Œå¯èƒ½æ˜¯å»å¹´
                    if month > datetime.now().month:
                        year -= 1
                    mask = mask & (df['_Date'].dt.month == month) & (df['_Date'].dt.year == year)
            
            # å®¢æˆ¶éæ¿¾
            if filters.get("customer"):
                customer = filters["customer"]
                mask = mask & (df['Customer'].astype(str).str.contains(customer, na=False, case=False))
            
            # æ¥­å‹™å“¡éæ¿¾
            if filters.get("worker"):
                worker = filters["worker"]
                mask = mask & (df['Worker'].astype(str).str.contains(worker, na=False, case=False))
            
            # ç‡Ÿæ¥­æ‰€éæ¿¾
            if filters.get("branch"):
                branch = filters["branch"]
                mask = mask & (df['Depart'].astype(str).str.contains(branch, na=False, case=False))
            
            # æ´»å‹•é¡å‹éæ¿¾
            if filters.get("activity_type"):
                activity = filters["activity_type"]
                mask = mask & (df['Class'].astype(str).str.contains(activity, na=False, case=False))
            
            # å¾æŸ¥è©¢æ–‡å­—ä¸­æå–é—œéµå­—ä½œç‚ºè£œå……éæ¿¾
            keywords_to_check = ['æ‹œè¨ª', 'é€è²¨', 'å ±åƒ¹', 'ç¶­ä¿®', 'æœƒè­°']
            for kw in keywords_to_check:
                if kw in query:
                    mask = mask & (df['Class'].astype(str).str.contains(kw, na=False))
                    break
            
            filtered = df[mask]
            
            # é¸æ“‡é¡¯ç¤ºçš„æ¬„ä½
            display_cols = ['Date', 'Worker', 'Customer', 'Class', 'Content', 'Depart']
            available_cols = [c for c in display_cols if c in filtered.columns]
            result = filtered[available_cols].copy()
            
            summary = {
                'total_records': len(result),
                'unique_workers': filtered['Worker'].nunique() if len(filtered) > 0 else 0,
                'unique_customers': filtered['Customer'].nunique() if len(filtered) > 0 else 0,
            }
            
            logger.info(f"Fallback æŸ¥è©¢çµæœ: {len(result)} ç­†è¨˜éŒ„")
            return result, summary, ""
            
        except Exception as e:
            error_msg = f"Fallback æŸ¥è©¢éŒ¯èª¤: {str(e)}"
            logger.error(error_msg)
            return None, {}, error_msg
    
    def _analyze_result(self, query: str, result: Any, summary: Dict) -> Dict:
        """ä½¿ç”¨ AI åˆ†æçµæœä¸¦ç”Ÿæˆæ´å¯Ÿ"""
        # æº–å‚™çµæœé è¦½
        if isinstance(result, pd.DataFrame):
            result_preview = result.head(20).to_string() if len(result) > 0 else "ç„¡æ•¸æ“š"
        elif isinstance(result, pd.Series):
            result_preview = result.head(20).to_string()
        elif isinstance(result, dict):
            result_preview = json.dumps(result, ensure_ascii=False, indent=2)
        else:
            result_preview = str(result)[:2000]
        
        prompt = ANALYSIS_PROMPT.format(
            query=query,
            summary=json.dumps(summary, ensure_ascii=False, default=str),
            result_preview=result_preview[:3000]  # é™åˆ¶é•·åº¦
        )
        
        try:
            response = self.llm.chat(prompt, temperature=0.2)
            
            # æ¸…ç† markdown æ¨™è¨˜
            response = response.strip()
            if response.startswith("```"):
                response = re.sub(r'^```\w*\n?', '', response)
                response = re.sub(r'\n?```$', '', response)
            
            return json.loads(response)
        except json.JSONDecodeError:
            # å¦‚æœ JSON è§£æå¤±æ•—ï¼Œè¿”å›ç´”æ–‡å­—å›ç­”
            return {
                "direct_answer": response[:500] if response else "åˆ†æå®Œæˆ",
                "insights": [],
                "recommendations": [],
            }
        except Exception as e:
            logger.error(f"çµæœåˆ†æå¤±æ•—: {e}")
            return {
                "direct_answer": "åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤",
                "insights": [],
                "recommendations": [],
            }
    
    def _format_output(self, query: str, result: Any, summary: Dict, 
                       analysis: Dict, code: str) -> AnalysisResult:
        """æ ¼å¼åŒ–æœ€çµ‚è¼¸å‡º"""
        # çµ„åˆè‡ªç„¶èªè¨€å›ç­”
        answer_parts = []
        
        # ç›´æ¥å›ç­”
        if analysis.get("direct_answer"):
            answer_parts.append(analysis["direct_answer"])
        
        # æ•¸æ“šæ‘˜è¦
        if summary:
            answer_parts.append("\n\nğŸ“Š **æ•¸æ“šæ‘˜è¦**")
            for k, v in summary.items():
                if k not in ('columns',):  # è·³éæŠ€è¡“æ¬„ä½
                    answer_parts.append(f"- {k}: {v}")
        
        # æ´å¯Ÿ
        if analysis.get("insights"):
            answer_parts.append("\n\nğŸ’¡ **é—œéµæ´å¯Ÿ**")
            for i, insight in enumerate(analysis["insights"], 1):
                answer_parts.append(f"{i}. {insight}")
        
        # è¶¨å‹¢
        if analysis.get("trends"):
            answer_parts.append("\n\nğŸ“ˆ **è¶¨å‹¢åˆ†æ**")
            for trend in analysis["trends"]:
                answer_parts.append(f"- {trend}")
        
        # ç•°å¸¸
        if analysis.get("anomalies"):
            answer_parts.append("\n\nâš ï¸ **å€¼å¾—æ³¨æ„**")
            for anomaly in analysis["anomalies"]:
                answer_parts.append(f"- {anomaly}")
        
        # å»ºè­°
        if analysis.get("recommendations"):
            answer_parts.append("\n\nâœ… **å»ºè­°è¡Œå‹•**")
            for rec in analysis["recommendations"]:
                answer_parts.append(f"- {rec}")
        
        # æ•¸æ“šè¡¨æ ¼ï¼ˆå¦‚æœæœ‰ï¼‰
        if isinstance(result, pd.DataFrame) and len(result) > 0 and len(result) <= 50:
            answer_parts.append("\n\nğŸ“‹ **è©³ç´°æ•¸æ“š**")
            answer_parts.append(self._df_to_markdown(result.head(30)))
        
        answer_parts.append("\n\nğŸ“‹ åƒè€ƒè³‡æ–™ä¾†æºï¼šbusiness")
        
        return AnalysisResult(
            answer="\n".join(answer_parts),
            data_summary=summary,
            insights=analysis.get("insights", []),
            recommendations=analysis.get("recommendations", []),
            visualizations=analysis.get("visualization_suggestions", []),
            raw_data=result if isinstance(result, (dict, list)) else None,
            code_executed=code,
            metadata={
                "query": query,
                "llm_model": self.llm.model,
                "timestamp": datetime.now().isoformat(),
            }
        )
    
    def _df_to_markdown(self, df: pd.DataFrame, max_rows: int = 30) -> str:
        """å°‡ DataFrame è½‰ç‚º Markdown è¡¨æ ¼"""
        if df.empty:
            return ""
        
        df_show = df.head(max_rows)
        cols = list(df_show.columns)
        
        # è¡¨é ­
        header = "| " + " | ".join(str(c) for c in cols) + " |"
        sep = "|" + "|".join(["---"] * len(cols)) + "|"
        
        # å…§å®¹
        rows = []
        for _, r in df_show.iterrows():
            row_vals = []
            for c in cols:
                val = str(r.get(c, ""))[:60]  # æˆªæ–·éé•·
                val = val.replace("|", "ï½œ").replace("\n", " ")
                row_vals.append(val)
            rows.append("| " + " | ".join(row_vals) + " |")
        
        return header + "\n" + sep + "\n" + "\n".join(rows)
    
    def query(self, query: str) -> Dict:
        """
        ä¸»æŸ¥è©¢å…¥å£
        
        Args:
            query: è‡ªç„¶èªè¨€æŸ¥è©¢
        
        Returns:
            {
                "answer": "è‡ªç„¶èªè¨€å›ç­”",
                "success": True/False,
                "data_summary": {...},
                "insights": [...],
                "recommendations": [...],
                "visualizations": [...],
                "metadata": {...}
            }
        """
        if not query or not query.strip():
            return {
                "answer": "è«‹è¼¸å…¥æœ‰æ•ˆçš„æŸ¥è©¢ã€‚",
                "success": False,
            }
        
        if self.df is None or self.df.empty:
            return {
                "answer": "æ¥­å‹™æ•¸æ“šæœªè¼‰å…¥ã€‚è«‹ç¢ºèª CSV æª”æ¡ˆæ˜¯å¦å­˜åœ¨ã€‚",
                "success": False,
            }
        
        try:
            # Step 1: AI è§£ææ„åœ–
            logger.info(f"ğŸ” è§£ææŸ¥è©¢æ„åœ–: {query[:50]}...")
            intent = self._parse_intent(query)
            logger.debug(f"æ„åœ–: {json.dumps(intent, ensure_ascii=False)}")
            
            # Step 2: AI ç”Ÿæˆä»£ç¢¼
            logger.info("ğŸ”§ ç”ŸæˆæŸ¥è©¢ä»£ç¢¼...")
            code = self._generate_code(query, intent)
            logger.debug(f"ç”Ÿæˆä»£ç¢¼:\n{code}")
            
            if not code:
                return {
                    "answer": "ç„¡æ³•ç”ŸæˆæŸ¥è©¢ä»£ç¢¼ã€‚è«‹å˜—è©¦æ›å€‹æ–¹å¼æè¿°æ‚¨çš„å•é¡Œã€‚",
                    "success": False,
                }
            
            # Step 3: åŸ·è¡Œä»£ç¢¼
            logger.info("âš¡ åŸ·è¡ŒæŸ¥è©¢...")
            result, summary, error = self._execute_code(code)
            
            if error:
                # ä»£ç¢¼åŸ·è¡Œå¤±æ•—ï¼Œå˜—è©¦ç°¡å–®çš„ fallback æŸ¥è©¢
                logger.warning(f"ä»£ç¢¼åŸ·è¡Œå¤±æ•—ï¼Œå˜—è©¦ fallback æŸ¥è©¢: {error}")
                result, summary, fallback_error = self._fallback_query(query, intent)
                
                if fallback_error or result is None:
                    return {
                        "answer": f"æŸ¥è©¢åŸ·è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚\n\næŠ€è¡“ç´°ç¯€ï¼š{error[:500]}",
                        "success": False,
                        "code": code,
                    }
                logger.info("âœ… Fallback æŸ¥è©¢æˆåŠŸ")
            
            if result is None or (isinstance(result, (pd.DataFrame, pd.Series)) and len(result) == 0):
                return {
                    "answer": "æŸ¥è©¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„æ•¸æ“šã€‚è«‹å˜—è©¦èª¿æ•´æŸ¥è©¢æ¢ä»¶ã€‚",
                    "success": True,
                    "data_summary": summary,
                }
            
            # Step 4: AI åˆ†æçµæœ
            logger.info("ğŸ“Š åˆ†æçµæœ...")
            analysis = self._analyze_result(query, result, summary)
            
            # Step 5: æ ¼å¼åŒ–è¼¸å‡º
            output = self._format_output(query, result, summary, analysis, code)
            
            return {
                "answer": output.answer,
                "success": True,
                "data_summary": output.data_summary,
                "insights": output.insights,
                "recommendations": output.recommendations,
                "visualizations": output.visualizations,
                "metadata": output.metadata,
            }
            
        except Exception as e:
            logger.error(f"æŸ¥è©¢å¤±æ•—: {e}\n{traceback.format_exc()}")
            return {
                "answer": f"æŸ¥è©¢éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}",
                "success": False,
            }
    
    def get_schema_info(self) -> Dict:
        """ç²å–æ•¸æ“š schema ä¿¡æ¯ï¼ˆä¾›å‰ç«¯ä½¿ç”¨ï¼‰"""
        if self.df is None:
            return {"loaded": False}
        
        return {
            "loaded": True,
            "total_records": len(self.df),
            "columns": list(self.df.columns),
            "date_range": {
                "min": self.df['_Date'].min().isoformat() if not self.df['_Date'].isna().all() else None,
                "max": self.df['_Date'].max().isoformat() if not self.df['_Date'].isna().all() else None,
            },
            "unique_values": {
                "workers": self.df['Worker'].nunique() if 'Worker' in self.df.columns else 0,
                "customers": self.df['Customer'].nunique() if 'Customer' in self.df.columns else 0,
                "branches": self.df['Depart'].unique().tolist() if 'Depart' in self.df.columns else [],
            },
            "sample_activity_types": self.df['Class'].value_counts().head(10).to_dict() if 'Class' in self.df.columns else {},
        }
    
    def get_quick_stats(self) -> Dict:
        """ç²å–å¿«é€Ÿçµ±è¨ˆï¼ˆå„€è¡¨æ¿ç”¨ï¼‰"""
        if self.df is None:
            return {}
        
        today = datetime.now().date()
        last_30_days = today - timedelta(days=30)
        
        recent = self.df[self.df['_Date'].dt.date >= last_30_days] if '_Date' in self.df.columns else self.df
        
        return {
            "total_records": len(self.df),
            "recent_30_days": len(recent),
            "active_workers": recent['Worker'].nunique() if 'Worker' in recent.columns else 0,
            "active_customers": recent['Customer'].nunique() if 'Customer' in recent.columns else 0,
            "top_activities": recent['Class'].value_counts().head(5).to_dict() if 'Class' in recent.columns else {},
            "by_branch": recent.groupby('Depart').size().to_dict() if 'Depart' in recent.columns else {},
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¾¿æ·å‡½æ•¸ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_engine: Optional[BusinessAIEngine] = None

def get_business_ai_engine() -> BusinessAIEngine:
    """ç²å–æ¥­å‹™ AI å¼•æ“å–®ä¾‹"""
    global _engine
    if _engine is None:
        _engine = BusinessAIEngine()
    return _engine

def ai_business_query(query: str) -> str:
    """
    AI æ¥­å‹™æŸ¥è©¢ï¼ˆç°¡åŒ–æ¥å£ï¼Œå‘å¾Œå…¼å®¹ï¼‰
    
    Args:
        query: è‡ªç„¶èªè¨€æŸ¥è©¢
    
    Returns:
        æ ¼å¼åŒ–çš„å›ç­”å­—ä¸²
    """
    engine = get_business_ai_engine()
    result = engine.query(query)
    return result.get("answer", "æŸ¥è©¢å¤±æ•—")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI æ¸¬è©¦
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import sys
    
    logging.basicConfig(level=logging.INFO)
    
    engine = BusinessAIEngine()
    
    print("\n" + "="*60)
    print("ğŸ¤– æ¥­å‹™ AI æŸ¥è©¢å¼•æ“ - äº’å‹•æ¨¡å¼")
    print("="*60)
    print(f"æ•¸æ“šç‹€æ…‹: {engine.get_schema_info()}")
    print("\nè¼¸å…¥ 'quit' é€€å‡º\n")
    
    while True:
        try:
            query = input("ğŸ“ æ‚¨çš„å•é¡Œ: ").strip()
            if query.lower() in ('quit', 'exit', 'q'):
                break
            if not query:
                continue
            
            print("\nâ³ è™•ç†ä¸­...\n")
            result = engine.query(query)
            print(result["answer"])
            print("\n" + "-"*60 + "\n")
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"éŒ¯èª¤: {e}")
    
    print("\nğŸ‘‹ å†è¦‹ï¼")

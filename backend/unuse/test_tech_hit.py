# test_tech_extract.py
# ç´”é›¢ç·šï¼šå¾ Markdown æŠ½å‡ºåŒ…å«ã€ŒNO.6500 / 6500 / 6500AC / 6502 / 6503ã€çš„æ®µè½åšé è¦½
# ç”¨æ³•ï¼š
#   python test_tech_extract.py --query "NO.6500 ç”¢å“å…§å®¹" \
#     --data-dir "data/markdown" --top-k 5

import argparse, glob, os, re
from typing import List, Tuple

def read_text(path: str) -> str:
    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        return f.read()

def list_md_files(root: str) -> List[str]:
    pats = ("**/*.md", "**/*.markdown", "**/*.txt")
    out = []
    for p in pats:
        out.extend(glob.glob(os.path.join(root, p), recursive=True))
    return sorted(set(out))

def make_patterns() -> List[re.Pattern]:
    pats = [
        r"\bNO[.\-_ ]?6500\b",
        r"\bN0[.\-_ ]?6500\b",        # N+é›¶ çš„èª¤æ‰“
        r"â„–\s*6500",                 # è¨˜è™Ÿ
        r"\b6500AC\b",
        r"\b6502\b",
        r"\b6503\b",
        r"\b6500\b",
    ]
    return [re.compile(p, re.IGNORECASE) for p in pats]

def cut_section_around_headings(txt: str, hit_pos: int) -> str:
    """ä»¥å‘½ä¸­é»ç‚ºä¸­å¿ƒï¼Œå¾€ä¸Šæ‰¾æœ€è¿‘çš„ #### æˆ– ### æˆ– ## ç•¶ä½œæ®µè½èµ·é»ï¼Œ
       å¾€ä¸‹åˆ°ä¸‹ä¸€å€‹åŒç´š/æ›´é«˜ç´šæ¨™é¡Œç‚ºæ­¢ã€‚è‹¥æ‰¾ä¸åˆ°å°±å– Â±1200 å­—ã€‚"""
    # æ‰¾åˆ°ä¸Šä¸€å€‹ heading
    up_iter = list(re.finditer(r"^(#{2,6})\s.*$", txt, flags=re.MULTILINE))
    start = max(0, hit_pos - 1200)
    end = min(len(txt), hit_pos + 1200)
    for m in up_iter:
        if m.start() <= hit_pos:
            start = m.start()
    # æ‰¾åˆ°ä¸‹ä¸€å€‹ heading
    for m in up_iter:
        if m.start() > hit_pos:
            end = m.start()
            break
    sect = txt[start:end]
    # ç°¡å–®æ¸…ç†ï¼šé€£çºŒç©ºç™½ã€éé•·è¡Œ
    sect = re.sub(r"[ \t]+\n", "\n", sect)
    sect = re.sub(r"\n{3,}", "\n\n", sect)
    return sect.strip()

def extract_hits_from_file(path: str, patterns: List[re.Pattern]) -> List[Tuple[int, str]]:
    txt = read_text(path)
    hits = []
    for pat in patterns:
        for m in pat.finditer(txt):
            pos = m.start()
            sect = cut_section_around_headings(txt, pos)
            hits.append((pos, sect))
    # å»é‡ï¼ˆä»¥å…§å®¹ç‚ºéµï¼‰
    uniq = []
    seen = set()
    for pos, s in hits:
        key = (path, s[:400])
        if key not in seen:
            seen.add(key)
            uniq.append((pos, s))
    return uniq

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--query", required=True)
    ap.add_argument("--data-dir", required=True)
    ap.add_argument("--top-k", type=int, default=5)
    args = ap.parse_args()

    files = list_md_files(args.data_dir)
    if not files:
        print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼š{args.data_dir}")
        return

    patterns = make_patterns()
    bucket = []
    for fp in files:
        try:
            hs = extract_hits_from_file(fp, patterns)
            if hs:
                bucket.append((fp, hs))
        except Exception as e:
            print(f"âš ï¸ è®€å–å¤±æ•— {fp}: {e}")

    if not bucket:
        print("âŒ æ²’æœ‰ä»»ä½•å‘½ä¸­ã€‚")
        return

    print(f"ğŸ¯ æœ‰ {len(bucket)} å€‹æª”æ¡ˆå‘½ä¸­ï¼Œé¡¯ç¤ºå‰ {args.top_k}ï¼š\n")
    shown = 0
    for fp, hs in bucket:
        print(f"ğŸ“„ {fp}")
        for idx, (pos, sect) in enumerate(hs[:2], 1):  # æ¯æª”æœ€å¤šé¡¯ç¤º 2 æ®µ
            print(f"  â”œâ”€ ç‰‡æ®µ#{idx} @ {pos}\n")
            # æŠŠ HTML æ¨™ç±¤å£“æ‰ä¸€éƒ¨åˆ†ï¼Œåˆ©æ–¼è®€
            preview = re.sub(r"<[^>]+>", "", sect)
            print(preview.strip())
            print("\n  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")
            shown += 1
            if shown >= args.top_k:
                print("âœ… Done.")
                return
    print("âœ… Done.")

if __name__ == "__main__":
    main()

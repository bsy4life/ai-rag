# local_image_debug.py - æœ¬åœ°ç‰ˆæœ¬çš„åœ–ç‰‡èª¿è©¦å·¥å…·
import os
import re
from pathlib import Path
from collections import defaultdict

def analyze_markdown_images(data_dir: str):
    """åˆ†æ Markdown æ–‡ä»¶ä¸­çš„åœ–ç‰‡å¼•ç”¨"""
    
    results = {
        'total_files': 0,
        'total_image_refs': 0,
        'by_pattern': defaultdict(int),
        'by_file': defaultdict(list),
        'unique_images': set(),
        'missing_images': [],
        'found_images': []
    }
    
    # ä¸åŒçš„åœ–ç‰‡åŒ¹é…æ¨¡å¼
    patterns = {
        'markdown_basic': r'!\[([^\]]*)\]\(([^)]+?)\)',
        'markdown_with_title': r'!\[([^\]]*)\]\(([^)]+?)(?:\s+"([^"]*)")?\)',
        'html_img_basic': r'<img[^>]+src=[\'"]+([^>\'"]+)[\'"]+[^>]*>',
        'html_img_with_alt': r'<img[^>]+src=[\'"]+([^>\'"]+)[\'"]+[^>]*(?:alt=[\'"]+([^>\'"]*?)[\'"]+)?[^>]*>',
        'html_img_with_style': r'<img[^>]+src=[\'"]+([^>\'"]+)[\'"]+[^>]*style=[^>]*>',
    }
    
    data_path = Path(data_dir)
    media_dir = data_path / "media"
    
    print(f"ğŸ” åˆ†æç›®éŒ„: {data_dir}")
    print(f"ğŸ–¼ï¸ åª’é«”ç›®éŒ„: {media_dir}")
    print(f"ğŸ“ è³‡æ–™ç›®éŒ„å­˜åœ¨: {'æ˜¯' if data_path.exists() else 'å¦'}")
    print(f"ğŸ“ åª’é«”ç›®éŒ„å­˜åœ¨: {'æ˜¯' if media_dir.exists() else 'å¦'}")
    
    if not data_path.exists():
        print(f"âŒ è³‡æ–™ç›®éŒ„ä¸å­˜åœ¨: {data_dir}")
        return results
    
    # éæ­·æ‰€æœ‰ Markdown æ–‡ä»¶
    md_files = list(data_path.rglob("*.md"))
    print(f"ğŸ“„ æ‰¾åˆ° Markdown æ–‡ä»¶: {len(md_files)} å€‹")
    
    for md_file in md_files:
        results['total_files'] += 1
        print(f"\nğŸ“„ è™•ç†æ–‡ä»¶: {md_file.name}")
        
        try:
            with open(md_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
        except Exception as e:
            print(f"   âŒ è®€å–å¤±æ•—: {e}")
            continue
        
        file_images = []
        
        # æ¸¬è©¦æ¯ç¨®æ¨¡å¼
        for pattern_name, pattern in patterns.items():
            matches = list(re.finditer(pattern, content, re.IGNORECASE))
            pattern_count = len(matches)
            
            if pattern_count > 0:
                print(f"   ğŸ“Š {pattern_name}: {pattern_count} å€‹åŒ¹é…")
                results['by_pattern'][pattern_name] += pattern_count
                
                for match in matches:
                    if 'src=' in match.group(0):  # HTML
                        img_path = match.group(1)
                    else:  # Markdown
                        img_path = match.group(2) if len(match.groups()) > 1 else match.group(1)
                    
                    file_images.append({
                        'pattern': pattern_name,
                        'path': img_path,
                        'match_text': match.group(0)[:100] + '...' if len(match.group(0)) > 100 else match.group(0)
                    })
                    
                    results['unique_images'].add(img_path)
        
        results['by_file'][md_file.name] = file_images
        results['total_image_refs'] += len(file_images)
        
        print(f"   ğŸ“Š æ–‡ä»¶ç¸½åœ–ç‰‡å¼•ç”¨: {len(file_images)}")
    
    # æª¢æŸ¥åœ–ç‰‡å¯¦éš›å­˜åœ¨æƒ…æ³
    print(f"\nğŸ” æª¢æŸ¥åœ–ç‰‡å¯¦éš›å­˜åœ¨æƒ…æ³...")
    for img_path in results['unique_images']:
        if _check_image_exists(img_path, media_dir, data_path):
            results['found_images'].append(img_path)
        else:
            results['missing_images'].append(img_path)
    
    return results

def _check_image_exists(img_path: str, media_base_dir: Path, data_dir: Path) -> bool:
    """æª¢æŸ¥åœ–ç‰‡æ˜¯å¦å­˜åœ¨"""
    clean_path = img_path.strip('\'"')
    
    # è™•ç†çµ•å°è·¯å¾‘
    if os.path.isabs(clean_path):
        path_parts = Path(clean_path).parts
        media_indices = [i for i, part in enumerate(path_parts) if part == 'media']
        
        if len(media_indices) >= 2:
            doc_folder_idx = media_indices[0] + 1
            img_name_idx = media_indices[1] + 1
            
            if doc_folder_idx < len(path_parts) and img_name_idx < len(path_parts):
                extracted_doc_name = path_parts[doc_folder_idx]
                img_name = path_parts[img_name_idx]
                
                local_path = media_base_dir / extracted_doc_name / "media" / img_name
                return local_path.exists()
    
    # è™•ç†ç›¸å°è·¯å¾‘
    img_name = Path(clean_path.lstrip('./')).name
    
    # åœ¨æ‰€æœ‰å¯èƒ½çš„ä½ç½®æœå°‹
    if media_base_dir.exists():
        for root, dirs, files in os.walk(media_base_dir):
            if img_name in files:
                return True
    
    return False

def print_analysis_report(results: dict):
    """æ‰“å°åˆ†æå ±å‘Š"""
    print(f"\n" + "="*60)
    print(f"ğŸ“Š åœ–ç‰‡åˆ†æå ±å‘Š")
    print(f"="*60)
    
    print(f"ğŸ“„ ç¸½æ–‡ä»¶æ•¸: {results['total_files']}")
    print(f"ğŸ–¼ï¸ ç¸½åœ–ç‰‡å¼•ç”¨æ•¸: {results['total_image_refs']}")
    print(f"ğŸ”— å”¯ä¸€åœ–ç‰‡è·¯å¾‘æ•¸: {len(results['unique_images'])}")
    print(f"âœ… å­˜åœ¨çš„åœ–ç‰‡: {len(results['found_images'])}")
    print(f"âŒ ç¼ºå¤±çš„åœ–ç‰‡: {len(results['missing_images'])}")
    
    print(f"\nğŸ“Š æŒ‰æ¨¡å¼åˆ†çµ„:")
    for pattern, count in results['by_pattern'].items():
        print(f"   {pattern}: {count}")
    
    print(f"\nğŸ“„ æŒ‰æ–‡ä»¶åˆ†çµ„:")
    for filename, images in results['by_file'].items():
        if images:  # åªé¡¯ç¤ºæœ‰åœ–ç‰‡çš„æ–‡ä»¶
            print(f"   {filename}: {len(images)} å¼µåœ–ç‰‡")
            # é¡¯ç¤ºå‰å¹¾å€‹åœ–ç‰‡è·¯å¾‘
            for img in images[:3]:
                print(f"      - {img['path']} ({img['pattern']})")
    
    if results['missing_images']:
        print(f"\nâŒ ç¼ºå¤±çš„åœ–ç‰‡ç¯„ä¾‹ï¼ˆå‰10å€‹ï¼‰:")
        for img_path in results['missing_images'][:10]:
            print(f"   {img_path}")
    
    if results['found_images']:
        print(f"\nâœ… å­˜åœ¨çš„åœ–ç‰‡ç¯„ä¾‹ï¼ˆå‰5å€‹ï¼‰:")
        for img_path in results['found_images'][:5]:
            print(f"   {img_path}")

def analyze_actual_media_directory(data_dir: str):
    """åˆ†æå¯¦éš›çš„åª’é«”ç›®éŒ„çµæ§‹"""
    media_dir = Path(data_dir) / "media"
    
    print(f"\nğŸ“ å¯¦éš›åª’é«”ç›®éŒ„åˆ†æ:")
    print(f"åª’é«”ç›®éŒ„è·¯å¾‘: {media_dir}")
    
    if not media_dir.exists():
        print(f"âŒ åª’é«”ç›®éŒ„ä¸å­˜åœ¨")
        return
    
    print(f"âœ… åª’é«”ç›®éŒ„å­˜åœ¨")
    
    total_actual_images = 0
    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp', '.tiff', '.tif'}
    
    for root, dirs, files in os.walk(media_dir):
        image_files = [f for f in files if Path(f).suffix.lower() in image_extensions]
        if image_files:
            rel_path = Path(root).relative_to(media_dir)
            print(f"   ğŸ“‚ {rel_path}: {len(image_files)} å¼µåœ–ç‰‡")
            total_actual_images += len(image_files)
            
            # é¡¯ç¤ºå‰å¹¾å€‹æª”æ¡ˆå
            for img_file in image_files[:3]:
                print(f"      - {img_file}")
            if len(image_files) > 3:
                print(f"      - ... é‚„æœ‰ {len(image_files) - 3} å¼µ")
    
    print(f"\nğŸ–¼ï¸ å¯¦éš›å­˜åœ¨çš„åœ–ç‰‡æª”æ¡ˆç¸½æ•¸: {total_actual_images}")
    
    return total_actual_images

def main():
    """ä¸»å‡½æ•¸"""
    # æœ¬åœ°è·¯å¾‘ - æ ¹æ“šæ‚¨çš„å¯¦éš›è·¯å¾‘èª¿æ•´
    possible_paths = [
        "data/markdown",  # ç›¸å°è·¯å¾‘
        "./data/markdown",  # ç•¶å‰ç›®éŒ„ä¸‹
        "../data/markdown",  # ä¸Šä¸€å±¤ç›®éŒ„
        os.path.expanduser("~/ai-rag/backend/data/markdown"),  # å®Œæ•´è·¯å¾‘
    ]
    
    data_dir = None
    for path in possible_paths:
        if Path(path).exists():
            data_dir = str(Path(path).resolve())
            print(f"âœ… æ‰¾åˆ°è³‡æ–™ç›®éŒ„: {data_dir}")
            break
    
    if not data_dir:
        print(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™ç›®éŒ„ï¼Œè«‹æ‰‹å‹•æŒ‡å®š:")
        print(f"å¯èƒ½çš„ä½ç½®:")
        for path in possible_paths:
            print(f"  - {Path(path).resolve()}")
        return
    
    print(f"ğŸš€ é–‹å§‹åœ–ç‰‡åˆ†æ...")
    
    # åˆ†æ Markdown ä¸­çš„åœ–ç‰‡å¼•ç”¨
    results = analyze_markdown_images(data_dir)
    print_analysis_report(results)
    
    # åˆ†æå¯¦éš›çš„åª’é«”ç›®éŒ„
    actual_count = analyze_actual_media_directory(data_dir)
    
    # ç¸½çµ
    print(f"\n" + "="*60)
    print(f"ğŸ“‹ ç¸½çµæ¯”è¼ƒ")
    print(f"="*60)
    print(f"Markdown ä¸­å¼•ç”¨çš„åœ–ç‰‡: {results['total_image_refs']}")
    print(f"å”¯ä¸€åœ–ç‰‡è·¯å¾‘: {len(results['unique_images'])}")
    print(f"å¯¦éš›å­˜åœ¨çš„åœ–ç‰‡æª”æ¡ˆ: {actual_count}")
    print(f"æ‰¾åˆ°çš„åœ–ç‰‡: {len(results['found_images'])}")
    print(f"ç¼ºå¤±çš„åœ–ç‰‡: {len(results['missing_images'])}")

if __name__ == "__main__":
    main()
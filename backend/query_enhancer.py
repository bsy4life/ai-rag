# query_enhancer.py - AI é©…å‹•çš„æŸ¥è©¢å¢å¼·å™¨
"""
åŠŸèƒ½ï¼š
1. å¤šèªè¨€è¡“èªç¿»è­¯ï¼ˆä¸­â†”æ—¥â†”è‹±ï¼‰
2. åŒç¾©è©æ“´å±•
3. ç”¢å“å‹è™Ÿè­˜åˆ¥èˆ‡ç²¾ç¢ºåŒ¹é…
4. æ„åœ–ç†è§£èˆ‡æŸ¥è©¢æ”¹å¯«
5. ç”Ÿæˆå¤šå€‹æœç´¢æŸ¥è©¢æé«˜å¬å›ç‡

ä½¿ç”¨ï¼š
    from query_enhancer import QueryEnhancer
    enhancer = QueryEnhancer()
    enhanced = enhancer.enhance(query)
    # enhanced.queries = ["å¢Šç‰‡ ã‚¬ã‚¹ã‚±ãƒƒãƒˆ gasket", "è€ç†± é«˜æ¸©ç”¨", ...]
"""

import os
import re
import json
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è¡“èªè©å…¸ï¼ˆéœæ…‹ï¼Œå¿«é€ŸæŸ¥æ‰¾ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TERM_DICTIONARY = {
    # ç”¢å“é¡å‹
    "å¢Šç‰‡": ["ã‚¬ã‚¹ã‚±ãƒƒãƒˆ", "gasket", "ãƒ‘ãƒƒã‚­ãƒ³", "packing", "ã‚·ãƒ¼ãƒˆã‚¬ã‚¹ã‚±ãƒƒãƒˆ"],
    "å¯†å°å¢Š": ["ã‚·ãƒ¼ãƒ«", "seal", "ã‚¬ã‚¹ã‚±ãƒƒãƒˆ", "gasket"],
    "è»Ÿè³ªå¢Šç‰‡": ["ã‚½ãƒ•ãƒˆã‚¬ã‚¹ã‚±ãƒƒãƒˆ", "soft gasket", "ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆã‚·ãƒ¼ãƒˆ"],
    "é‡‘å±¬å¢Šç‰‡": ["ãƒ¡ã‚¿ãƒ«ã‚¬ã‚¹ã‚±ãƒƒãƒˆ", "metal gasket", "é‡‘å±ã‚¬ã‚¹ã‚±ãƒƒãƒˆ"],
    "æ¸¦å·å¢Šç‰‡": ["ã†ãšå·»å½¢ã‚¬ã‚¹ã‚±ãƒƒãƒˆ", "spiral wound gasket", "ã‚¹ãƒ‘ã‚¤ãƒ©ãƒ«ã‚¬ã‚¹ã‚±ãƒƒãƒˆ"],
    "æ²¹å°": ["ã‚ªã‚¤ãƒ«ã‚·ãƒ¼ãƒ«", "oil seal", "ã‚·ãƒ¼ãƒ«"],
    "Oç’°": ["Oãƒªãƒ³ã‚°", "O-ring", "ã‚ªãƒ¼ãƒªãƒ³ã‚°"],
    "å¡«æ–™": ["ãƒ‘ãƒƒã‚­ãƒ³", "packing", "ã‚°ãƒ©ãƒ³ãƒ‰ãƒ‘ãƒƒã‚­ãƒ³"],
    "æ°£ç¼¸": ["ã‚·ãƒªãƒ³ãƒ€", "cylinder", "ã‚¨ã‚¢ã‚·ãƒªãƒ³ãƒ€", "air cylinder"],
    "é›»ç£é–¥": ["ã‚½ãƒ¬ãƒã‚¤ãƒ‰ãƒãƒ«ãƒ–", "solenoid valve", "é›»ç£å¼"],
    "èª¿å£“é–¥": ["ãƒ¬ã‚®ãƒ¥ãƒ¬ãƒ¼ã‚¿", "regulator", "æ¸›åœ§å¼", "pressure regulator"],
    "éæ¿¾å™¨": ["ãƒ•ã‚£ãƒ«ã‚¿", "filter", "æ¿¾éå™¨"],
    "æ¥é ­": ["ç¶™æ‰‹", "fitting", "connector", "ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°"],
    "æ¶ˆéŸ³å™¨": ["ã‚µã‚¤ãƒ¬ãƒ³ã‚µ", "silencer", "muffler"],
    "çœŸç©ºå¸ç›¤": ["çœŸç©ºãƒ‘ãƒƒãƒ‰", "vacuum pad", "å¸ç€ãƒ‘ãƒƒãƒ‰", "ã‚µã‚¯ã‚·ãƒ§ãƒ³ã‚«ãƒƒãƒ—"],
    "çœŸç©ºç”¢ç”Ÿå™¨": ["çœŸç©ºã‚¨ã‚¸ã‚§ã‚¯ã‚¿", "vacuum ejector", "ãƒã‚­ãƒ¥ãƒ¼ãƒ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿"],
    "å£“åŠ›é–‹é—œ": ["åœ§åŠ›ã‚¹ã‚¤ãƒƒãƒ", "pressure switch"],
    "æµé‡é–‹é—œ": ["ãƒ•ãƒ­ãƒ¼ã‚¹ã‚¤ãƒƒãƒ", "flow switch"],
    "é›»å‹•è‡´å‹•å™¨": ["é›»å‹•ã‚¢ã‚¯ãƒãƒ¥ã‚¨ãƒ¼ã‚¿", "electric actuator"],
    
    # VALQUA ç”¢å“ç³»åˆ—
    "6500": ["ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆã‚·ãƒ¼ãƒˆã‚¬ã‚¹ã‚±ãƒƒãƒˆ", "joint sheet", "No.6500"],
    "7010": ["ãƒãƒ«ãƒ•ãƒ­ãƒ³ã‚·ãƒ¼ãƒˆ", "PTFE sheet", "ãµã£ç´ æ¨¹è„‚ã‚·ãƒ¼ãƒˆ"],
    "7020": ["ãƒãƒ«ãƒ•ãƒ­ãƒ³ã‚·ãƒ¼ãƒˆ", "PTFE gasket", "ãµã£ç´ æ¨¹è„‚ã‚¬ã‚¹ã‚±ãƒƒãƒˆ"],
    
    # æè³ª
    "ä¸é½é‹¼": ["ã‚¹ãƒ†ãƒ³ãƒ¬ã‚¹", "stainless steel", "SUS"],
    "é‹": ["ã‚¢ãƒ«ãƒŸ", "aluminum", "aluminium"],
    "é»ƒéŠ…": ["çœŸé®", "brass"],
    "æ°Ÿç´ æ¨¹è„‚": ["ãµã£ç´ æ¨¹è„‚", "PTFE", "ãƒ†ãƒ•ãƒ­ãƒ³", "fluororesin", "ãƒ•ãƒƒç´ "],
    "æ©¡è† ": ["ã‚´ãƒ ", "rubber"],
    "NBR": ["ãƒ‹ãƒˆãƒªãƒ«ã‚´ãƒ ", "nitrile rubber", "ä¸è…ˆæ©¡è† "],
    "EPDM": ["ã‚¨ãƒãƒ¬ãƒ³ãƒ—ãƒ­ãƒ”ãƒ¬ãƒ³ã‚´ãƒ ", "ethylene propylene"],
    "çŸ½è† ": ["ã‚·ãƒªã‚³ãƒ¼ãƒ³", "silicone"],
    "çŸ³å¢¨": ["ã‚°ãƒ©ãƒ•ã‚¡ã‚¤ãƒˆ", "graphite", "è†¨å¼µé»’é‰›"],
    
    # ç‰¹æ€§
    "è€ç†±": ["è€ç†±æ€§", "é«˜æ¸©ç”¨", "heat resistant", "high temperature", "é«˜æ¸©"],
    "è€å£“": ["è€åœ§", "pressure resistant", "é«˜åœ§ç”¨", "é«˜åœ§"],
    "è€è…è•": ["è€é£Ÿ", "è€è•", "corrosion resistant", "é˜²è•", "è€è–¬å“"],
    "è€æ²¹": ["è€æ²¹æ€§", "oil resistant"],
    "çœŸç©º": ["ãƒã‚­ãƒ¥ãƒ¼ãƒ ", "vacuum", "çœŸç©ºç”¨"],
    "é˜²çˆ†": ["é˜²çˆ†å½¢", "explosion proof", "è€åœ§é˜²çˆ†"],
    "é£Ÿå“ç´š": ["é£Ÿå“ç”¨", "food grade", "é£Ÿå“è¡›ç”Ÿæ³•é©åˆ"],
    "ç„¡å¡µ": ["ã‚¯ãƒªãƒ¼ãƒ³", "clean", "ã‚¯ãƒªãƒ¼ãƒ³ãƒ«ãƒ¼ãƒ ç”¨", "ä½ç™ºå¡µ"],
    
    # å‹•ä½œ/æ“ä½œ
    "å®‰è£": ["å–ä»˜", "å–ã‚Šä»˜ã‘", "installation", "mounting", "è¨­ç½®", "çµ„ä»˜"],
    "æ‹†å¸": ["å–ã‚Šå¤–ã—", "removal", "åˆ†è§£"],
    "èª¿æ•´": ["èª¿ç¯€", "adjustment", "ã‚»ãƒƒãƒ†ã‚£ãƒ³ã‚°"],
    "ç¶­ä¿®": ["ä¿®ç†", "ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹", "maintenance", "ä¿å®ˆ"],
    "æ•…éšœ": ["ãƒˆãƒ©ãƒ–ãƒ«", "trouble", "æ•…éšœ", "ç•°å¸¸"],
    "æ¼æ°£": ["ã‚¨ã‚¢ãƒªãƒ¼ã‚¯", "air leak", "æ¼ã‚Œ"],
    "æ¼æ²¹": ["ã‚ªã‚¤ãƒ«ãƒªãƒ¼ã‚¯", "oil leak", "æ²¹æ¼ã‚Œ"],
    "é¸å‹": ["é¸å®š", "selection", "å‹å¼é¸å®š"],
    
    # è¦æ ¼/å°ºå¯¸
    "è¦æ ¼": ["ä»•æ§˜", "specification", "spec", "ã‚¹ãƒšãƒƒã‚¯"],
    "å°ºå¯¸": ["å¯¸æ³•", "dimension", "ã‚µã‚¤ã‚º", "size"],
    "å£å¾‘": ["å£å¾„", "bore size", "å‘¼ã³å¾„"],
    "è¡Œç¨‹": ["ã‚¹ãƒˆãƒ­ãƒ¼ã‚¯", "stroke"],
    "å£“åŠ›": ["åœ§åŠ›", "pressure"],
    "æº«åº¦": ["æ¸©åº¦", "temperature"],
    "æµé‡": ["æµé‡", "flow rate"],
}

# å“ç‰Œåˆ¥å
BRAND_ALIASES = {
    "SMC": ["smc", "ã‚¨ã‚¹ã‚¨ãƒ ã‚·ãƒ¼"],
    "VALQUA": ["valqua", "ãƒãƒ«ã‚«ãƒ¼", "è¯çˆ¾å¡", "valker"],
    "ç–åŸº": ["jiuji", "ä¹…åŸº", "GF"],
    "å”é‹¼": ["xiegang", "å”é‹¼æ²¹å°"],
    "æ²¹ç ”": ["YUKEN", "yuken", "ãƒ¦ã‚±ãƒ³"],
    "CKD": ["ckd", "ã‚·ãƒ¼ã‚±ãƒ¼ãƒ‡ã‚£"],
    "FESTO": ["festo", "ãƒ•ã‚§ã‚¹ãƒˆ"],
    "NOK": ["nok", "ã‚¨ãƒŒã‚ªãƒ¼ã‚±ãƒ¼"],
}

# ç”¢å“å‹è™Ÿæ­£å‰‡
MODEL_PATTERNS = {
    "smc": [
        r'\b(?:MXJ|MXH|MXP|MXQ|MXS|MXW|MXF)[\d]+[A-Z]?[-\d\w]*\b',  # æ°£ç¼¸
        r'\b(?:LES|LEH|LEJ|LEY|LEF|LEL)[\dA-Z][-\w]*\b',  # é›»å‹•è‡´å‹•å™¨
        r'\b(?:SY|SV|SQ|VQ|VQZ|VF|VFS)[\d]+[-\w]*\b',  # é›»ç£é–¥
        r'\b(?:ACG|ARG|AWG|AFM|AFF|AF)[\d]*[-\w]*\b',  # ç©ºå£“è™•ç†
        r'\b(?:ZSE|ZSP|ZSM|ISE|ISA)[\d]+[A-Z]*[-\w]*\b',  # å£“åŠ›é–‹é—œ
        r'\b(?:KQ|KQG|KQB|KQH|KJ|KJH)[\d]*[-\w]*\b',  # æ¥é ­
        r'\b(?:CDQ|CQ|CDJ|CJ|C[A-Z]{1,2})[\d]+[-\w]*\b',  # æ›´å¤šæ°£ç¼¸
    ],
    "valqua": [
        r'\b(?:No\.?\s*)?[67]\d{3}[A-Z]?\b',  # 6500, 7020 ç­‰
        r'\b(?:No\.?\s*)?\d{4}[-\w]*\b',  # ä¸€èˆ¬ç”¢å“è™Ÿ
        r'\b(?:HRS|VG|VS)[-\d\w]*\b',  # ç‰¹æ®Šç³»åˆ—
    ],
    "seal": [
        r'\bGF[-\s]?\d+[-\w]*\b',  # ç–åŸºæ²¹å°
        r'\b(?:TC|TB|SC|SA|TA)\s*\d+[xXÃ—]\d+[xXÃ—]\d+\b',  # æ²¹å°å°ºå¯¸è¦æ ¼
    ],
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ•¸æ“šé¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class EnhancedQuery:
    """å¢å¼·å¾Œçš„æŸ¥è©¢çµæœ"""
    original: str                           # åŸå§‹æŸ¥è©¢
    intent: str = ""                        # ç†è§£çš„æ„åœ–
    primary_query: str = ""                 # ä¸»è¦æœç´¢æŸ¥è©¢
    expanded_queries: List[str] = field(default_factory=list)  # å±•é–‹çš„å¤šå€‹æŸ¥è©¢
    extracted_models: List[str] = field(default_factory=list)  # æå–çš„ç”¢å“å‹è™Ÿ
    detected_brand: str = ""                # åµæ¸¬åˆ°çš„å“ç‰Œ
    language_variants: Dict[str, str] = field(default_factory=dict)  # å¤šèªè¨€è®Šé«”
    keywords: List[str] = field(default_factory=list)  # æå–çš„é—œéµå­—
    
    def get_all_queries(self) -> List[str]:
        """ç²å–æ‰€æœ‰æŸ¥è©¢ï¼ˆç”¨æ–¼å¤šæ¬¡æœç´¢ï¼‰"""
        queries = [self.primary_query] if self.primary_query else [self.original]
        queries.extend(self.expanded_queries)
        # åŠ å…¥ç”¢å“å‹è™Ÿä½œç‚ºç¨ç«‹æŸ¥è©¢ï¼ˆç²¾ç¢ºåŒ¹é…ï¼‰
        queries.extend(self.extracted_models)
        return list(dict.fromkeys(queries))  # å»é‡ä¿åº


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LLM å®¢æˆ¶ç«¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LLMClient:
    """ç°¡æ˜“ LLM å®¢æˆ¶ç«¯"""
    
    def __init__(self):
        self.provider = os.getenv("LLM_PROVIDER", "openai").strip().lower()
        
        # è™•ç† auto æ¨¡å¼
        if self.provider == "auto":
            primary = os.getenv("LLM_PRIMARY", "anthropic").strip().lower()
            self.provider = "anthropic" if primary in ("anthropic", "claude") else "openai"
        
        self._client = None
        self._init_client()
    
    def _init_client(self):
        if self.provider == "anthropic" and os.getenv("ANTHROPIC_API_KEY"):
            try:
                from anthropic import Anthropic
                self._client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
                self.model = os.getenv("ANTHROPIC_MODEL_SIMPLE", "claude-haiku-4-5-20251001")
                logger.debug(f"QueryEnhancer ä½¿ç”¨ Anthropic: {self.model}")
            except ImportError:
                self._init_openai()
        else:
            self._init_openai()
    
    def _init_openai(self):
        if os.getenv("OPENAI_API_KEY"):
            try:
                from openai import OpenAI
                self._client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                self.provider = "openai"
                self.model = os.getenv("OPENAI_MODEL_SIMPLE", "gpt-4o-mini")
                logger.debug(f"QueryEnhancer ä½¿ç”¨ OpenAI: {self.model}")
            except ImportError:
                logger.warning("ç„¡æ³•åˆå§‹åŒ– LLM å®¢æˆ¶ç«¯")
                self._client = None
    
    def chat(self, prompt: str, system: str = None) -> str:
        if not self._client:
            return ""
        
        try:
            if self.provider == "anthropic":
                kwargs = {
                    "model": self.model,
                    "max_tokens": 1000,
                    "messages": [{"role": "user", "content": prompt}],
                }
                if system:
                    kwargs["system"] = system
                response = self._client.messages.create(**kwargs)
                return response.content[0].text
            else:
                messages = []
                if system:
                    messages.append({"role": "system", "content": system})
                messages.append({"role": "user", "content": prompt})
                response = self._client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    max_tokens=1000,
                    temperature=0.1,
                )
                return response.choices[0].message.content
        except Exception as e:
            error_msg = str(e)
            # é™é¡éŒ¯èª¤æ™‚å˜—è©¦ fallback
            if "usage limits" in error_msg or "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
                logger.warning(f"âš ï¸ QueryEnhancer {self.provider} é™é¡ï¼Œå˜—è©¦ fallback")
                return self._fallback_chat(prompt, system)
            logger.error(f"LLM èª¿ç”¨å¤±æ•—: {e}")
            return ""
    
    def _fallback_chat(self, prompt: str, system: str = None) -> str:
        """Fallback åˆ°å¦ä¸€å€‹æä¾›å•†"""
        try:
            if self.provider == "anthropic" and os.getenv("OPENAI_API_KEY"):
                from openai import OpenAI
                client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
                model = os.getenv("OPENAI_MODEL_SIMPLE", "gpt-4o-mini")
                messages = []
                if system:
                    messages.append({"role": "system", "content": system})
                messages.append({"role": "user", "content": prompt})
                response = client.chat.completions.create(
                    model=model, messages=messages, max_tokens=1000, temperature=0.1,
                )
                logger.info(f"âœ… QueryEnhancer fallback åˆ° OpenAI æˆåŠŸ")
                return response.choices[0].message.content
            elif self.provider == "openai" and os.getenv("ANTHROPIC_API_KEY"):
                from anthropic import Anthropic
                client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
                model = os.getenv("ANTHROPIC_MODEL_SIMPLE", "claude-haiku-4-5-20251001")
                kwargs = {"model": model, "max_tokens": 1000, "messages": [{"role": "user", "content": prompt}]}
                if system:
                    kwargs["system"] = system
                response = client.messages.create(**kwargs)
                logger.info(f"âœ… QueryEnhancer fallback åˆ° Anthropic æˆåŠŸ")
                return response.content[0].text
        except Exception as e:
            logger.error(f"âŒ QueryEnhancer fallback ä¹Ÿå¤±æ•—: {e}")
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æŸ¥è©¢å¢å¼·å™¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class QueryEnhancer:
    """AI é©…å‹•çš„æŸ¥è©¢å¢å¼·å™¨"""
    
    def __init__(self, use_llm: bool = True):
        """
        Args:
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM é€²è¡Œæ·±åº¦ç†è§£ï¼ˆè¨­ç‚º False å‰‡åªç”¨è¦å‰‡ï¼‰
        """
        self.use_llm = use_llm
        self._llm = None
        if use_llm:
            try:
                self._llm = LLMClient()
            except Exception as e:
                logger.warning(f"LLM åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡åªä½¿ç”¨è¦å‰‡: {e}")
                self.use_llm = False
    
    def enhance(self, query: str) -> EnhancedQuery:
        """
        å¢å¼·æŸ¥è©¢
        
        Args:
            query: åŸå§‹ç”¨æˆ¶æŸ¥è©¢
        
        Returns:
            EnhancedQuery å°è±¡
        """
        result = EnhancedQuery(original=query)
        
        # 1. æå–ç”¢å“å‹è™Ÿï¼ˆç²¾ç¢ºåŒ¹é…æœ€é‡è¦ï¼‰
        result.extracted_models = self._extract_models(query)
        result.detected_brand = self._detect_brand(query)
        
        # 2. è¦å‰‡å¼æ“´å±•ï¼ˆå¿«é€Ÿï¼Œç„¡éœ€ LLMï¼‰
        result.keywords = self._extract_keywords(query)
        result.language_variants = self._translate_terms(query)
        
        # 3. æ§‹å»ºä¸»è¦æŸ¥è©¢
        result.primary_query = self._build_primary_query(query, result)
        
        # 4. ä½¿ç”¨ LLM æ·±åº¦ç†è§£ï¼ˆå¯é¸ï¼‰
        if self.use_llm and self._llm and self._llm._client:
            llm_enhanced = self._llm_enhance(query)
            if llm_enhanced:
                result.intent = llm_enhanced.get("intent", "")
                result.expanded_queries.extend(llm_enhanced.get("queries", []))
        
        # 5. ç”Ÿæˆæ“´å±•æŸ¥è©¢
        result.expanded_queries.extend(self._generate_expanded_queries(query, result))
        
        # å»é‡
        result.expanded_queries = list(dict.fromkeys(result.expanded_queries))
        
        logger.info(f"ğŸ“ æŸ¥è©¢å¢å¼·: '{query}' â†’ {len(result.get_all_queries())} å€‹æŸ¥è©¢è®Šé«”")
        
        return result
    
    def _extract_models(self, query: str) -> List[str]:
        """æå–ç”¢å“å‹è™Ÿ"""
        models = []
        
        for brand, patterns in MODEL_PATTERNS.items():
            for pattern in patterns:
                matches = re.findall(pattern, query, re.IGNORECASE)
                for m in matches:
                    if isinstance(m, tuple):
                        m = m[0]
                    if m and len(m) >= 2:
                        models.append(m.upper())
        
        return list(set(models))
    
    def _detect_brand(self, query: str) -> str:
        """åµæ¸¬å“ç‰Œ"""
        query_upper = query.upper()
        
        for brand, aliases in BRAND_ALIASES.items():
            if brand.upper() in query_upper:
                return brand
            for alias in aliases:
                if alias.upper() in query_upper:
                    return brand
        
        # æ ¹æ“šç”¢å“å‹è™Ÿæ¨æ–·
        for brand, patterns in MODEL_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, query, re.IGNORECASE):
                    return brand.upper()
        
        return ""
    
    def _extract_keywords(self, query: str) -> List[str]:
        """æå–é—œéµå­—"""
        keywords = []
        
        for term in TERM_DICTIONARY.keys():
            if term in query:
                keywords.append(term)
        
        return keywords
    
    def _translate_terms(self, query: str) -> Dict[str, str]:
        """ç¿»è­¯è¡“èªåˆ°å¤šèªè¨€"""
        variants = {"original": query}
        
        ja_terms = []
        en_terms = []
        
        for zh_term, translations in TERM_DICTIONARY.items():
            if zh_term in query:
                # ç¬¬ä¸€å€‹é€šå¸¸æ˜¯æ—¥æ–‡ï¼Œç¬¬äºŒå€‹æ˜¯è‹±æ–‡
                if translations:
                    ja_terms.append(translations[0])
                if len(translations) > 1:
                    en_terms.append(translations[1])
        
        if ja_terms:
            variants["japanese"] = " ".join(ja_terms)
        if en_terms:
            variants["english"] = " ".join(en_terms)
        
        return variants
    
    def _build_primary_query(self, query: str, result: EnhancedQuery) -> str:
        """æ§‹å»ºä¸»è¦æœç´¢æŸ¥è©¢"""
        parts = [query]
        
        # åŠ å…¥å“ç‰Œé—œéµå­—
        if result.detected_brand:
            parts.append(result.detected_brand)
        
        # åŠ å…¥å¤šèªè¨€è¡“èª
        for lang, text in result.language_variants.items():
            if lang != "original" and text:
                parts.append(text)
        
        return " ".join(parts)
    
    def _llm_enhance(self, query: str) -> Optional[Dict]:
        """ä½¿ç”¨ LLM é€²è¡Œæ·±åº¦æŸ¥è©¢å¢å¼·"""
        
        prompt = f"""åˆ†æä»¥ä¸‹å·¥æ¥­ç”¢å“æŸ¥è©¢ï¼Œç†è§£ç”¨æˆ¶æ„åœ–ä¸¦ç”Ÿæˆæœç´¢æŸ¥è©¢è®Šé«”ã€‚

ç”¨æˆ¶æŸ¥è©¢ï¼š{query}

è«‹å›ç­” JSON æ ¼å¼ï¼š
{{
    "intent": "ç”¨æˆ¶æƒ³è¦æ‰¾ä»€éº¼ï¼ˆç°¡çŸ­æè¿°ï¼‰",
    "queries": [
        "æœç´¢æŸ¥è©¢1ï¼ˆåŠ å…¥æ—¥æ–‡è¡“èªï¼‰",
        "æœç´¢æŸ¥è©¢2ï¼ˆåŠ å…¥è‹±æ–‡è¡“èªï¼‰",
        "æœç´¢æŸ¥è©¢3ï¼ˆåŒç¾©è©è®Šé«”ï¼‰"
    ]
}}

æ³¨æ„ï¼š
- é€™æ˜¯å·¥æ¥­è¨­å‚™ç”¢å“ç›®éŒ„æœç´¢
- å¸¸è¦‹å“ç‰Œï¼šSMCï¼ˆæ°£å£“è¨­å‚™ï¼‰ã€VALQUA/è¯çˆ¾å¡ï¼ˆå¢Šç‰‡ï¼‰ã€ç–åŸºï¼ˆæ²¹å°ï¼‰
- è¦è€ƒæ…®ä¸­æ—¥è‹±ä¸‰èªè¡“èª
- åªå›ç­” JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—"""

        system = "ä½ æ˜¯ä¸€å€‹å·¥æ¥­ç”¢å“æœç´¢åŠ©æ‰‹ï¼Œå°ˆé–€å¹«åŠ©æ“´å±•æœç´¢æŸ¥è©¢ä»¥æé«˜å¬å›ç‡ã€‚"
        
        try:
            response = self._llm.chat(prompt, system)
            
            # æ¸…ç† markdown
            response = response.strip()
            if response.startswith("```"):
                response = re.sub(r'^```\w*\n?', '', response)
                response = re.sub(r'\n?```$', '', response)
            
            return json.loads(response)
        except Exception as e:
            logger.warning(f"LLM å¢å¼·å¤±æ•—: {e}")
            return None
    
    def _generate_expanded_queries(self, query: str, result: EnhancedQuery) -> List[str]:
        """ç”Ÿæˆæ“´å±•æŸ¥è©¢"""
        expanded = []
        
        # åŸºæ–¼é—œéµå­—çš„æ“´å±•
        for keyword in result.keywords:
            if keyword in TERM_DICTIONARY:
                for trans in TERM_DICTIONARY[keyword][:2]:
                    # æ›¿æ›åŸæŸ¥è©¢ä¸­çš„é—œéµå­—
                    expanded_q = query.replace(keyword, f"{keyword} {trans}")
                    if expanded_q != query:
                        expanded.append(expanded_q)
        
        # å“ç‰Œæ“´å±•
        if result.detected_brand:
            brand_aliases = BRAND_ALIASES.get(result.detected_brand, [])
            for alias in brand_aliases[:2]:
                expanded.append(f"{query} {alias}")
        
        # æ—¥æ–‡ç‰ˆæŸ¥è©¢ï¼ˆå¦‚æœæœ‰ç¿»è­¯ï¼‰
        if result.language_variants.get("japanese"):
            expanded.append(result.language_variants["japanese"])
        
        return expanded


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¾¿æ·å‡½æ•¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_enhancer_instance = None

def get_query_enhancer(use_llm: bool = True) -> QueryEnhancer:
    """ç²å–æŸ¥è©¢å¢å¼·å™¨å–®ä¾‹"""
    global _enhancer_instance
    if _enhancer_instance is None:
        _enhancer_instance = QueryEnhancer(use_llm=use_llm)
    return _enhancer_instance


def enhance_query(query: str, use_llm: bool = True) -> EnhancedQuery:
    """å¢å¼·æŸ¥è©¢çš„ä¾¿æ·å‡½æ•¸"""
    return get_query_enhancer(use_llm).enhance(query)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ¸¬è©¦
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)
    
    test_queries = [
        "æœ‰æ²’æœ‰è€é«˜æº«çš„å¢Šç‰‡ï¼Ÿ",
        "SMC MXJ6-5 æ°£ç¼¸è¦æ ¼",
        "çœŸç©ºå¸ç›¤å®‰è£æ–¹æ³•",
        "VALQUA 7020 å¢Šç‰‡æè³ª",
        "æ²¹å°æ¼æ²¹æ€éº¼è™•ç†",
        "ZSE30A å£“åŠ›é–‹é—œ",
    ]
    
    enhancer = QueryEnhancer(use_llm=False)  # å…ˆç”¨è¦å‰‡æ¸¬è©¦
    
    for q in test_queries:
        print(f"\n{'='*50}")
        print(f"åŸå§‹: {q}")
        result = enhancer.enhance(q)
        print(f"æ„åœ–: {result.intent}")
        print(f"å‹è™Ÿ: {result.extracted_models}")
        print(f"å“ç‰Œ: {result.detected_brand}")
        print(f"æŸ¥è©¢è®Šé«”:")
        for i, qv in enumerate(result.get_all_queries()[:5], 1):
            print(f"  {i}. {qv}")
